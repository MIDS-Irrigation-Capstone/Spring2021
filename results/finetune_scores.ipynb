{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "determined-romania",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-prefix",
   "metadata": {},
   "source": [
    "## Consolidated Results For Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "declared-envelope",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>labeling</th>\n",
       "      <th>split_percent</th>\n",
       "      <th>pretrain</th>\n",
       "      <th>loss</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "      <th>f1</th>\n",
       "      <th>f0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BEN</td>\n",
       "      <td>balanced</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.394389</td>\n",
       "      <td>1889.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.828740</td>\n",
       "      <td>0.773230</td>\n",
       "      <td>0.930084</td>\n",
       "      <td>0.895239</td>\n",
       "      <td>0.844435</td>\n",
       "      <td>0.819286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BEN</td>\n",
       "      <td>expanded</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.459749</td>\n",
       "      <td>5007.0</td>\n",
       "      <td>1836.0</td>\n",
       "      <td>3652.0</td>\n",
       "      <td>481.0</td>\n",
       "      <td>0.788903</td>\n",
       "      <td>0.731697</td>\n",
       "      <td>0.912354</td>\n",
       "      <td>0.860625</td>\n",
       "      <td>0.812100</td>\n",
       "      <td>0.783405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BEN</td>\n",
       "      <td>expanded</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.632764</td>\n",
       "      <td>4655.0</td>\n",
       "      <td>1811.0</td>\n",
       "      <td>3677.0</td>\n",
       "      <td>833.0</td>\n",
       "      <td>0.759111</td>\n",
       "      <td>0.719920</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>0.815952</td>\n",
       "      <td>0.778819</td>\n",
       "      <td>0.758143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BEN</td>\n",
       "      <td>expanded</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.507432</td>\n",
       "      <td>5027.0</td>\n",
       "      <td>2054.0</td>\n",
       "      <td>3437.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.771137</td>\n",
       "      <td>0.709928</td>\n",
       "      <td>0.916500</td>\n",
       "      <td>0.831861</td>\n",
       "      <td>0.800095</td>\n",
       "      <td>0.767598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BEN</td>\n",
       "      <td>expanded</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>0.482517</td>\n",
       "      <td>4336.0</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>4084.0</td>\n",
       "      <td>1148.0</td>\n",
       "      <td>0.767128</td>\n",
       "      <td>0.754875</td>\n",
       "      <td>0.790664</td>\n",
       "      <td>0.841841</td>\n",
       "      <td>0.772355</td>\n",
       "      <td>0.766439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BEN</td>\n",
       "      <td>balanced</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.468172</td>\n",
       "      <td>1602.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>1560.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>0.778051</td>\n",
       "      <td>0.772420</td>\n",
       "      <td>0.788386</td>\n",
       "      <td>0.864622</td>\n",
       "      <td>0.780321</td>\n",
       "      <td>0.777670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BEN</td>\n",
       "      <td>balanced</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.601744</td>\n",
       "      <td>1736.0</td>\n",
       "      <td>718.0</td>\n",
       "      <td>1313.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.750246</td>\n",
       "      <td>0.707416</td>\n",
       "      <td>0.853911</td>\n",
       "      <td>0.799443</td>\n",
       "      <td>0.773791</td>\n",
       "      <td>0.750324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BEN</td>\n",
       "      <td>balanced</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.429256</td>\n",
       "      <td>1755.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1531.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>0.808563</td>\n",
       "      <td>0.778270</td>\n",
       "      <td>0.863256</td>\n",
       "      <td>0.880372</td>\n",
       "      <td>0.818563</td>\n",
       "      <td>0.804677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BEN</td>\n",
       "      <td>expanded</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.467871</td>\n",
       "      <td>4880.0</td>\n",
       "      <td>1690.0</td>\n",
       "      <td>3795.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>0.790361</td>\n",
       "      <td>0.742770</td>\n",
       "      <td>0.888727</td>\n",
       "      <td>0.855676</td>\n",
       "      <td>0.809220</td>\n",
       "      <td>0.785787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BEN</td>\n",
       "      <td>expanded</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.474145</td>\n",
       "      <td>4275.0</td>\n",
       "      <td>1234.0</td>\n",
       "      <td>4255.0</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>0.777150</td>\n",
       "      <td>0.776003</td>\n",
       "      <td>0.779114</td>\n",
       "      <td>0.854385</td>\n",
       "      <td>0.777555</td>\n",
       "      <td>0.777037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BEN</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>0.414822</td>\n",
       "      <td>1773.0</td>\n",
       "      <td>538.0</td>\n",
       "      <td>1492.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>0.803396</td>\n",
       "      <td>0.767200</td>\n",
       "      <td>0.871681</td>\n",
       "      <td>0.882509</td>\n",
       "      <td>0.816110</td>\n",
       "      <td>0.799129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BEN</td>\n",
       "      <td>balanced</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.420994</td>\n",
       "      <td>1685.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>1618.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>0.812746</td>\n",
       "      <td>0.802763</td>\n",
       "      <td>0.829232</td>\n",
       "      <td>0.890809</td>\n",
       "      <td>0.815783</td>\n",
       "      <td>0.811396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CA_sgd</td>\n",
       "      <td>expanded</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.424037</td>\n",
       "      <td>4861.0</td>\n",
       "      <td>1449.0</td>\n",
       "      <td>4040.0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>0.810951</td>\n",
       "      <td>0.770365</td>\n",
       "      <td>0.885912</td>\n",
       "      <td>0.883357</td>\n",
       "      <td>0.824108</td>\n",
       "      <td>0.805379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CA_sgd</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>0.399917</td>\n",
       "      <td>1887.0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.824065</td>\n",
       "      <td>0.768010</td>\n",
       "      <td>0.928642</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>0.840722</td>\n",
       "      <td>0.815001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CA_sgd</td>\n",
       "      <td>balanced</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.493672</td>\n",
       "      <td>1699.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>1528.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>0.794045</td>\n",
       "      <td>0.771221</td>\n",
       "      <td>0.836122</td>\n",
       "      <td>0.861226</td>\n",
       "      <td>0.802361</td>\n",
       "      <td>0.791705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CA_sgd</td>\n",
       "      <td>expanded</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.458954</td>\n",
       "      <td>4635.0</td>\n",
       "      <td>1452.0</td>\n",
       "      <td>4039.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>0.790270</td>\n",
       "      <td>0.761459</td>\n",
       "      <td>0.845032</td>\n",
       "      <td>0.861744</td>\n",
       "      <td>0.801072</td>\n",
       "      <td>0.787417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CA_sgd</td>\n",
       "      <td>balanced</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.355194</td>\n",
       "      <td>1804.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>1608.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>0.839567</td>\n",
       "      <td>0.811151</td>\n",
       "      <td>0.886051</td>\n",
       "      <td>0.915509</td>\n",
       "      <td>0.846948</td>\n",
       "      <td>0.834670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CA_sgd</td>\n",
       "      <td>expanded</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.504122</td>\n",
       "      <td>4062.0</td>\n",
       "      <td>1061.0</td>\n",
       "      <td>4427.0</td>\n",
       "      <td>1426.0</td>\n",
       "      <td>0.773415</td>\n",
       "      <td>0.792895</td>\n",
       "      <td>0.740160</td>\n",
       "      <td>0.849554</td>\n",
       "      <td>0.765621</td>\n",
       "      <td>0.774501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CA_sgd</td>\n",
       "      <td>balanced</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.397361</td>\n",
       "      <td>1899.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>1464.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.827510</td>\n",
       "      <td>0.770698</td>\n",
       "      <td>0.933170</td>\n",
       "      <td>0.898676</td>\n",
       "      <td>0.844188</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CA_sgd</td>\n",
       "      <td>expanded</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.448634</td>\n",
       "      <td>4844.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>4059.0</td>\n",
       "      <td>643.0</td>\n",
       "      <td>0.811133</td>\n",
       "      <td>0.772075</td>\n",
       "      <td>0.882814</td>\n",
       "      <td>0.876649</td>\n",
       "      <td>0.823739</td>\n",
       "      <td>0.805767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CA_sgd</td>\n",
       "      <td>expanded</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.441597</td>\n",
       "      <td>4279.0</td>\n",
       "      <td>995.0</td>\n",
       "      <td>4491.0</td>\n",
       "      <td>1211.0</td>\n",
       "      <td>0.799016</td>\n",
       "      <td>0.811339</td>\n",
       "      <td>0.779417</td>\n",
       "      <td>0.879669</td>\n",
       "      <td>0.795058</td>\n",
       "      <td>0.800412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CA_sgd</td>\n",
       "      <td>expanded</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>0.461821</td>\n",
       "      <td>4830.0</td>\n",
       "      <td>1574.0</td>\n",
       "      <td>3917.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.796921</td>\n",
       "      <td>0.754216</td>\n",
       "      <td>0.880583</td>\n",
       "      <td>0.866063</td>\n",
       "      <td>0.812516</td>\n",
       "      <td>0.792106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CA_sgd</td>\n",
       "      <td>balanced</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.432705</td>\n",
       "      <td>1691.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>1580.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>0.804872</td>\n",
       "      <td>0.788713</td>\n",
       "      <td>0.832595</td>\n",
       "      <td>0.880461</td>\n",
       "      <td>0.810060</td>\n",
       "      <td>0.802817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CA_sgd</td>\n",
       "      <td>balanced</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.370097</td>\n",
       "      <td>1735.0</td>\n",
       "      <td>381.0</td>\n",
       "      <td>1648.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.832431</td>\n",
       "      <td>0.819943</td>\n",
       "      <td>0.852580</td>\n",
       "      <td>0.910474</td>\n",
       "      <td>0.835943</td>\n",
       "      <td>0.830541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CA_adam</td>\n",
       "      <td>balanced</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>2.189502</td>\n",
       "      <td>1799.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>1746.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0.872293</td>\n",
       "      <td>0.862830</td>\n",
       "      <td>0.885335</td>\n",
       "      <td>0.894910</td>\n",
       "      <td>0.873937</td>\n",
       "      <td>0.870203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CA_adam</td>\n",
       "      <td>expanded</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>8.248110</td>\n",
       "      <td>4009.0</td>\n",
       "      <td>1301.0</td>\n",
       "      <td>4187.0</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.746720</td>\n",
       "      <td>0.754991</td>\n",
       "      <td>0.730503</td>\n",
       "      <td>0.762571</td>\n",
       "      <td>0.742545</td>\n",
       "      <td>0.746648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>CA_adam</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>6.069070</td>\n",
       "      <td>1787.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1646.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>0.844734</td>\n",
       "      <td>0.823123</td>\n",
       "      <td>0.878564</td>\n",
       "      <td>0.856991</td>\n",
       "      <td>0.849941</td>\n",
       "      <td>0.840809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>CA_adam</td>\n",
       "      <td>balanced</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>1.581498</td>\n",
       "      <td>1881.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>0.876969</td>\n",
       "      <td>0.844255</td>\n",
       "      <td>0.924779</td>\n",
       "      <td>0.902685</td>\n",
       "      <td>0.882684</td>\n",
       "      <td>0.869492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>CA_adam</td>\n",
       "      <td>balanced</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>43.199074</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>603.0</td>\n",
       "      <td>1431.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>0.752461</td>\n",
       "      <td>0.729596</td>\n",
       "      <td>0.801478</td>\n",
       "      <td>0.754978</td>\n",
       "      <td>0.763850</td>\n",
       "      <td>0.752080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CA_adam</td>\n",
       "      <td>balanced</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.830275</td>\n",
       "      <td>1679.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>1811.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>0.858760</td>\n",
       "      <td>0.883684</td>\n",
       "      <td>0.826280</td>\n",
       "      <td>0.917181</td>\n",
       "      <td>0.854018</td>\n",
       "      <td>0.863683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>CA_adam</td>\n",
       "      <td>expanded</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>1.338757</td>\n",
       "      <td>3980.0</td>\n",
       "      <td>908.0</td>\n",
       "      <td>4582.0</td>\n",
       "      <td>1506.0</td>\n",
       "      <td>0.780066</td>\n",
       "      <td>0.814239</td>\n",
       "      <td>0.725483</td>\n",
       "      <td>0.846835</td>\n",
       "      <td>0.767303</td>\n",
       "      <td>0.782335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>CA_adam</td>\n",
       "      <td>expanded</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.763182</td>\n",
       "      <td>4074.0</td>\n",
       "      <td>663.0</td>\n",
       "      <td>4823.0</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>0.810587</td>\n",
       "      <td>0.860038</td>\n",
       "      <td>0.742077</td>\n",
       "      <td>0.892206</td>\n",
       "      <td>0.796715</td>\n",
       "      <td>0.816760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>CA_adam</td>\n",
       "      <td>balanced</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>18.838003</td>\n",
       "      <td>1582.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>1669.0</td>\n",
       "      <td>451.0</td>\n",
       "      <td>0.799951</td>\n",
       "      <td>0.813786</td>\n",
       "      <td>0.778160</td>\n",
       "      <td>0.804820</td>\n",
       "      <td>0.795575</td>\n",
       "      <td>0.801554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>CA_adam</td>\n",
       "      <td>expanded</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>2.914803</td>\n",
       "      <td>4615.0</td>\n",
       "      <td>1293.0</td>\n",
       "      <td>4196.0</td>\n",
       "      <td>872.0</td>\n",
       "      <td>0.802751</td>\n",
       "      <td>0.781144</td>\n",
       "      <td>0.841079</td>\n",
       "      <td>0.830218</td>\n",
       "      <td>0.810004</td>\n",
       "      <td>0.800150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>CA_adam</td>\n",
       "      <td>expanded</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>42.837402</td>\n",
       "      <td>3755.0</td>\n",
       "      <td>1334.0</td>\n",
       "      <td>4158.0</td>\n",
       "      <td>1729.0</td>\n",
       "      <td>0.720937</td>\n",
       "      <td>0.737866</td>\n",
       "      <td>0.684719</td>\n",
       "      <td>0.724754</td>\n",
       "      <td>0.710300</td>\n",
       "      <td>0.719257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>CA_adam</td>\n",
       "      <td>expanded</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.523797</td>\n",
       "      <td>4861.0</td>\n",
       "      <td>1221.0</td>\n",
       "      <td>4265.0</td>\n",
       "      <td>629.0</td>\n",
       "      <td>0.831450</td>\n",
       "      <td>0.799244</td>\n",
       "      <td>0.885428</td>\n",
       "      <td>0.900907</td>\n",
       "      <td>0.840131</td>\n",
       "      <td>0.826045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  labeling  split_percent  pretrain       loss      tp      fp  \\\n",
       "0       BEN  balanced            100     False   0.394389  1889.0   554.0   \n",
       "1       BEN  expanded            100     False   0.459749  5007.0  1836.0   \n",
       "2       BEN  expanded              1     False   0.632764  4655.0  1811.0   \n",
       "3       BEN  expanded              3     False   0.507432  5027.0  2054.0   \n",
       "4       BEN  expanded             10     False   0.482517  4336.0  1408.0   \n",
       "5       BEN  balanced              3     False   0.468172  1602.0   472.0   \n",
       "6       BEN  balanced              1     False   0.601744  1736.0   718.0   \n",
       "7       BEN  balanced             25     False   0.429256  1755.0   500.0   \n",
       "8       BEN  expanded             25     False   0.467871  4880.0  1690.0   \n",
       "9       BEN  expanded             50     False   0.474145  4275.0  1234.0   \n",
       "10      BEN  balanced             10     False   0.414822  1773.0   538.0   \n",
       "11      BEN  balanced             50     False   0.420994  1685.0   414.0   \n",
       "12   CA_sgd  expanded            100     False   0.424037  4861.0  1449.0   \n",
       "13   CA_sgd  balanced             10     False   0.399917  1887.0   570.0   \n",
       "14   CA_sgd  balanced              1     False   0.493672  1699.0   504.0   \n",
       "15   CA_sgd  expanded              3     False   0.458954  4635.0  1452.0   \n",
       "16   CA_sgd  balanced            100     False   0.355194  1804.0   420.0   \n",
       "17   CA_sgd  expanded              1     False   0.504122  4062.0  1061.0   \n",
       "18   CA_sgd  balanced             25     False   0.397361  1899.0   565.0   \n",
       "19   CA_sgd  expanded             25     False   0.448634  4844.0  1430.0   \n",
       "20   CA_sgd  expanded             50     False   0.441597  4279.0   995.0   \n",
       "21   CA_sgd  expanded             10     False   0.461821  4830.0  1574.0   \n",
       "22   CA_sgd  balanced              3     False   0.432705  1691.0   453.0   \n",
       "23   CA_sgd  balanced             50     False   0.370097  1735.0   381.0   \n",
       "24  CA_adam  balanced             25     False   2.189502  1799.0   286.0   \n",
       "25  CA_adam  expanded              3     False   8.248110  4009.0  1301.0   \n",
       "26  CA_adam  balanced             10     False   6.069070  1787.0   384.0   \n",
       "27  CA_adam  balanced             50     False   1.581498  1881.0   347.0   \n",
       "28  CA_adam  balanced              1     False  43.199074  1627.0   603.0   \n",
       "29  CA_adam  balanced            100     False   0.830275  1679.0   221.0   \n",
       "30  CA_adam  expanded             25     False   1.338757  3980.0   908.0   \n",
       "31  CA_adam  expanded             50     False   0.763182  4074.0   663.0   \n",
       "32  CA_adam  balanced              3     False  18.838003  1582.0   362.0   \n",
       "33  CA_adam  expanded             10     False   2.914803  4615.0  1293.0   \n",
       "34  CA_adam  expanded              1     False  42.837402  3755.0  1334.0   \n",
       "35  CA_adam  expanded            100     False   0.523797  4861.0  1221.0   \n",
       "\n",
       "        tn      fn  accuracy  precision    recall       auc        f1  \\\n",
       "0   1479.0   142.0  0.828740   0.773230  0.930084  0.895239  0.844435   \n",
       "1   3652.0   481.0  0.788903   0.731697  0.912354  0.860625  0.812100   \n",
       "2   3677.0   833.0  0.759111   0.719920  0.848214  0.815952  0.778819   \n",
       "3   3437.0   458.0  0.771137   0.709928  0.916500  0.831861  0.800095   \n",
       "4   4084.0  1148.0  0.767128   0.754875  0.790664  0.841841  0.772355   \n",
       "5   1560.0   430.0  0.778051   0.772420  0.788386  0.864622  0.780321   \n",
       "6   1313.0   297.0  0.750246   0.707416  0.853911  0.799443  0.773791   \n",
       "7   1531.0   278.0  0.808563   0.778270  0.863256  0.880372  0.818563   \n",
       "8   3795.0   611.0  0.790361   0.742770  0.888727  0.855676  0.809220   \n",
       "9   4255.0  1212.0  0.777150   0.776003  0.779114  0.854385  0.777555   \n",
       "10  1492.0   261.0  0.803396   0.767200  0.871681  0.882509  0.816110   \n",
       "11  1618.0   347.0  0.812746   0.802763  0.829232  0.890809  0.815783   \n",
       "12  4040.0   626.0  0.810951   0.770365  0.885912  0.883357  0.824108   \n",
       "13  1462.0   145.0  0.824065   0.768010  0.928642  0.894000  0.840722   \n",
       "14  1528.0   333.0  0.794045   0.771221  0.836122  0.861226  0.802361   \n",
       "15  4039.0   850.0  0.790270   0.761459  0.845032  0.861744  0.801072   \n",
       "16  1608.0   232.0  0.839567   0.811151  0.886051  0.915509  0.846948   \n",
       "17  4427.0  1426.0  0.773415   0.792895  0.740160  0.849554  0.765621   \n",
       "18  1464.0   136.0  0.827510   0.770698  0.933170  0.898676  0.844188   \n",
       "19  4059.0   643.0  0.811133   0.772075  0.882814  0.876649  0.823739   \n",
       "20  4491.0  1211.0  0.799016   0.811339  0.779417  0.879669  0.795058   \n",
       "21  3917.0   655.0  0.796921   0.754216  0.880583  0.866063  0.812516   \n",
       "22  1580.0   340.0  0.804872   0.788713  0.832595  0.880461  0.810060   \n",
       "23  1648.0   300.0  0.832431   0.819943  0.852580  0.910474  0.835943   \n",
       "24  1746.0   233.0  0.872293   0.862830  0.885335  0.894910  0.873937   \n",
       "25  4187.0  1479.0  0.746720   0.754991  0.730503  0.762571  0.742545   \n",
       "26  1646.0   247.0  0.844734   0.823123  0.878564  0.856991  0.849941   \n",
       "27  1683.0   153.0  0.876969   0.844255  0.924779  0.902685  0.882684   \n",
       "28  1431.0   403.0  0.752461   0.729596  0.801478  0.754978  0.763850   \n",
       "29  1811.0   353.0  0.858760   0.883684  0.826280  0.917181  0.854018   \n",
       "30  4582.0  1506.0  0.780066   0.814239  0.725483  0.846835  0.767303   \n",
       "31  4823.0  1416.0  0.810587   0.860038  0.742077  0.892206  0.796715   \n",
       "32  1669.0   451.0  0.799951   0.813786  0.778160  0.804820  0.795575   \n",
       "33  4196.0   872.0  0.802751   0.781144  0.841079  0.830218  0.810004   \n",
       "34  4158.0  1729.0  0.720937   0.737866  0.684719  0.724754  0.710300   \n",
       "35  4265.0   629.0  0.831450   0.799244  0.885428  0.900907  0.840131   \n",
       "\n",
       "        f0.5  \n",
       "0   0.819286  \n",
       "1   0.783405  \n",
       "2   0.758143  \n",
       "3   0.767598  \n",
       "4   0.766439  \n",
       "5   0.777670  \n",
       "6   0.750324  \n",
       "7   0.804677  \n",
       "8   0.785787  \n",
       "9   0.777037  \n",
       "10  0.799129  \n",
       "11  0.811396  \n",
       "12  0.805379  \n",
       "13  0.815001  \n",
       "14  0.791705  \n",
       "15  0.787417  \n",
       "16  0.834670  \n",
       "17  0.774501  \n",
       "18  0.818182  \n",
       "19  0.805767  \n",
       "20  0.800412  \n",
       "21  0.792106  \n",
       "22  0.802817  \n",
       "23  0.830541  \n",
       "24  0.870203  \n",
       "25  0.746648  \n",
       "26  0.840809  \n",
       "27  0.869492  \n",
       "28  0.752080  \n",
       "29  0.863683  \n",
       "30  0.782335  \n",
       "31  0.816760  \n",
       "32  0.801554  \n",
       "33  0.800150  \n",
       "34  0.719257  \n",
       "35  0.826045  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the consolidated results and graph the performance of balanced and extended labels\n",
    "DIR = \".\"\n",
    "df = pd.read_csv(os.path.join(DIR, 'finetune_results.csv'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "funded-people",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>split_percent</th>\n",
       "      <th>pretrain</th>\n",
       "      <th>architecture</th>\n",
       "      <th>loss</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "      <th>f1</th>\n",
       "      <th>f0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>supervised_baseline</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>InceptionV3</td>\n",
       "      <td>0.186335</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>1788.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.939250</td>\n",
       "      <td>0.900732</td>\n",
       "      <td>0.986967</td>\n",
       "      <td>0.973556</td>\n",
       "      <td>0.941880</td>\n",
       "      <td>0.927752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>supervised_baseline</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>ResNet101V2</td>\n",
       "      <td>0.186999</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.934500</td>\n",
       "      <td>0.897931</td>\n",
       "      <td>0.979930</td>\n",
       "      <td>0.973764</td>\n",
       "      <td>0.937140</td>\n",
       "      <td>0.923695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>supervised_baseline</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.243032</td>\n",
       "      <td>1926.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>1795.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.915600</td>\n",
       "      <td>0.891254</td>\n",
       "      <td>0.946903</td>\n",
       "      <td>0.951272</td>\n",
       "      <td>0.918236</td>\n",
       "      <td>0.909062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>supervised_baseline</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>0.186086</td>\n",
       "      <td>1947.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>1784.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.932750</td>\n",
       "      <td>0.903061</td>\n",
       "      <td>0.970105</td>\n",
       "      <td>0.970995</td>\n",
       "      <td>0.935383</td>\n",
       "      <td>0.924355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>supervised_baseline</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>Xception</td>\n",
       "      <td>0.170726</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>1776.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.939750</td>\n",
       "      <td>0.899320</td>\n",
       "      <td>0.990510</td>\n",
       "      <td>0.976170</td>\n",
       "      <td>0.942715</td>\n",
       "      <td>0.927792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>supervised_baseline_pretrained_ex</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>InceptionV3</td>\n",
       "      <td>0.427894</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>1561.0</td>\n",
       "      <td>3929.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>0.811224</td>\n",
       "      <td>0.761169</td>\n",
       "      <td>0.906854</td>\n",
       "      <td>0.891291</td>\n",
       "      <td>0.827649</td>\n",
       "      <td>0.804235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>supervised_baseline_pretrained_ex</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>ResNet101V2</td>\n",
       "      <td>0.379863</td>\n",
       "      <td>4707.0</td>\n",
       "      <td>1044.0</td>\n",
       "      <td>4447.0</td>\n",
       "      <td>778.0</td>\n",
       "      <td>0.834001</td>\n",
       "      <td>0.818466</td>\n",
       "      <td>0.858159</td>\n",
       "      <td>0.909031</td>\n",
       "      <td>0.837843</td>\n",
       "      <td>0.831283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>supervised_baseline_pretrained_ex</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.515150</td>\n",
       "      <td>4587.0</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>4027.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>0.784803</td>\n",
       "      <td>0.758307</td>\n",
       "      <td>0.835976</td>\n",
       "      <td>0.863440</td>\n",
       "      <td>0.795250</td>\n",
       "      <td>0.782542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>supervised_baseline_pretrained_ex</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>0.604424</td>\n",
       "      <td>4641.0</td>\n",
       "      <td>1410.0</td>\n",
       "      <td>4082.0</td>\n",
       "      <td>843.0</td>\n",
       "      <td>0.794734</td>\n",
       "      <td>0.766981</td>\n",
       "      <td>0.846280</td>\n",
       "      <td>0.863395</td>\n",
       "      <td>0.804681</td>\n",
       "      <td>0.791709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>supervised_baseline_pretrained_ex</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>Xception</td>\n",
       "      <td>0.383450</td>\n",
       "      <td>4752.0</td>\n",
       "      <td>963.0</td>\n",
       "      <td>4525.0</td>\n",
       "      <td>736.0</td>\n",
       "      <td>0.845208</td>\n",
       "      <td>0.831496</td>\n",
       "      <td>0.865889</td>\n",
       "      <td>0.918018</td>\n",
       "      <td>0.848344</td>\n",
       "      <td>0.842653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model_type  split_percent  pretrain architecture  \\\n",
       "0                  supervised_baseline            100     False  InceptionV3   \n",
       "1                  supervised_baseline            100     False  ResNet101V2   \n",
       "2                  supervised_baseline            100     False    ResNet152   \n",
       "3                  supervised_baseline            100     False     ResNet50   \n",
       "4                  supervised_baseline            100     False     Xception   \n",
       "..                                 ...            ...       ...          ...   \n",
       "115  supervised_baseline_pretrained_ex             50      True  InceptionV3   \n",
       "116  supervised_baseline_pretrained_ex             50      True  ResNet101V2   \n",
       "117  supervised_baseline_pretrained_ex             50      True    ResNet152   \n",
       "118  supervised_baseline_pretrained_ex             50      True     ResNet50   \n",
       "119  supervised_baseline_pretrained_ex             50      True     Xception   \n",
       "\n",
       "         loss      tp      fp      tn     fn  accuracy  precision    recall  \\\n",
       "0    0.186335  1969.0   217.0  1788.0   26.0  0.939250   0.900732  0.986967   \n",
       "1    0.186999  1953.0   222.0  1785.0   40.0  0.934500   0.897931  0.979930   \n",
       "2    0.243032  1926.0   235.0  1795.0  108.0  0.915600   0.891254  0.946903   \n",
       "3    0.186086  1947.0   209.0  1784.0   60.0  0.932750   0.903061  0.970105   \n",
       "4    0.170726  1983.0   222.0  1776.0   19.0  0.939750   0.899320  0.990510   \n",
       "..        ...     ...     ...     ...    ...       ...        ...       ...   \n",
       "115  0.427894  4975.0  1561.0  3929.0  511.0  0.811224   0.761169  0.906854   \n",
       "116  0.379863  4707.0  1044.0  4447.0  778.0  0.834001   0.818466  0.858159   \n",
       "117  0.515150  4587.0  1462.0  4027.0  900.0  0.784803   0.758307  0.835976   \n",
       "118  0.604424  4641.0  1410.0  4082.0  843.0  0.794734   0.766981  0.846280   \n",
       "119  0.383450  4752.0   963.0  4525.0  736.0  0.845208   0.831496  0.865889   \n",
       "\n",
       "          auc        f1      f0.5  \n",
       "0    0.973556  0.941880  0.927752  \n",
       "1    0.973764  0.937140  0.923695  \n",
       "2    0.951272  0.918236  0.909062  \n",
       "3    0.970995  0.935383  0.924355  \n",
       "4    0.976170  0.942715  0.927792  \n",
       "..        ...       ...       ...  \n",
       "115  0.891291  0.827649  0.804235  \n",
       "116  0.909031  0.837843  0.831283  \n",
       "117  0.863440  0.795250  0.782542  \n",
       "118  0.863395  0.804681  0.791709  \n",
       "119  0.918018  0.848344  0.842653  \n",
       "\n",
       "[120 rows x 15 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(os.path.join(DIR, 'supervised_results.csv'))\n",
    "df2 = df2.drop(['Unnamed: 0'], axis = 1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "surprised-share",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>split_percent</th>\n",
       "      <th>pretrain</th>\n",
       "      <th>architecture</th>\n",
       "      <th>loss</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "      <th>f1</th>\n",
       "      <th>f0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>supervised</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.243032</td>\n",
       "      <td>1926.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>1795.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.915600</td>\n",
       "      <td>0.891254</td>\n",
       "      <td>0.946903</td>\n",
       "      <td>0.951272</td>\n",
       "      <td>0.918236</td>\n",
       "      <td>0.909062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>supervised</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.303365</td>\n",
       "      <td>1907.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.885581</td>\n",
       "      <td>0.848310</td>\n",
       "      <td>0.938946</td>\n",
       "      <td>0.939483</td>\n",
       "      <td>0.891330</td>\n",
       "      <td>0.876513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>supervised</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.455079</td>\n",
       "      <td>1349.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>1809.0</td>\n",
       "      <td>685.0</td>\n",
       "      <td>0.777067</td>\n",
       "      <td>0.859236</td>\n",
       "      <td>0.663225</td>\n",
       "      <td>0.902077</td>\n",
       "      <td>0.748613</td>\n",
       "      <td>0.782180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>supervised</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.274974</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>1668.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.907726</td>\n",
       "      <td>0.848447</td>\n",
       "      <td>0.993120</td>\n",
       "      <td>0.947509</td>\n",
       "      <td>0.915101</td>\n",
       "      <td>0.891749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>supervised</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.439815</td>\n",
       "      <td>1425.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>1871.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>0.897921</td>\n",
       "      <td>0.701625</td>\n",
       "      <td>0.919590</td>\n",
       "      <td>0.787728</td>\n",
       "      <td>0.821326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>supervised</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.193318</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.936516</td>\n",
       "      <td>0.904372</td>\n",
       "      <td>0.976401</td>\n",
       "      <td>0.964253</td>\n",
       "      <td>0.939007</td>\n",
       "      <td>0.927171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model  split_percent  pretrain architecture      loss      tp     fp  \\\n",
       "2   supervised            100     False    ResNet152  0.243032  1926.0  235.0   \n",
       "7   supervised             10     False    ResNet152  0.303365  1907.0  341.0   \n",
       "12  supervised              1     False    ResNet152  0.455079  1349.0  221.0   \n",
       "17  supervised             25     False    ResNet152  0.274974  2021.0  361.0   \n",
       "22  supervised              3     False    ResNet152  0.439815  1425.0  162.0   \n",
       "27  supervised             50     False    ResNet152  0.193318  1986.0  210.0   \n",
       "\n",
       "        tn     fn  accuracy  precision    recall       auc        f1      f0.5  \n",
       "2   1795.0  108.0  0.915600   0.891254  0.946903  0.951272  0.918236  0.909062  \n",
       "7   1692.0  124.0  0.885581   0.848310  0.938946  0.939483  0.891330  0.876513  \n",
       "12  1809.0  685.0  0.777067   0.859236  0.663225  0.902077  0.748613  0.782180  \n",
       "17  1668.0   14.0  0.907726   0.848447  0.993120  0.947509  0.915101  0.891749  \n",
       "22  1871.0  606.0  0.811024   0.897921  0.701625  0.919590  0.787728  0.821326  \n",
       "27  1820.0   48.0  0.936516   0.904372  0.976401  0.964253  0.939007  0.927171  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df2 = df2[(df2.model_type.isin(['supervised_baseline'])) & \n",
    "           (df2.architecture == 'ResNet152') &\n",
    "           (df2.pretrain == False)]\n",
    "_df2 = _df2.rename(columns = {'model_type' : 'model'})\n",
    "_df2['model'] = 'supervised'\n",
    "_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "opened-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(plot_df, xlab, ylab, title = None):\n",
    "    _title = \"Accuracy for different CNN Architectures\" if not title else title\n",
    "    \n",
    "    plot_df.plot(kind=\"bar\", figsize=(6,4), #marker = '.',\n",
    "                 rot=90, ylim=(0.4, 1.0), fontsize=10)\n",
    "    plt.title(_title, fontsize=10)\n",
    "    plt.legend(fontsize=8, loc = 'lower right')\n",
    "    plt.xlabel(xlab, fontsize=10)\n",
    "    plt.ylabel(ylab, fontsize=10)\n",
    "    \n",
    "def convert_to_plot(df, score, series, xlbl):\n",
    "    plot_df = df[[score, series, xlbl]]\n",
    "    plot_df = plot_df.pivot(\n",
    "        index= xlbl, \n",
    "        columns= series, \n",
    "        values= score\n",
    "    ).sort_values(xlbl, ascending=True)\n",
    "    return plot_df\n",
    "\n",
    "def display_results(dataframe, title):\n",
    "    display(dataframe)\n",
    "    plot_df = convert_to_plot(dataframe, 'accuracy', \"model\", \"split_percent\",)\n",
    "    plot_results(plot_df, \"Split Percentage\", \"accuracy\", f'Accuracy for {title}')\n",
    "    #plt.savefig(f\"{model_type}.png\")\n",
    "    \n",
    "    plot_df = convert_to_plot(dataframe, 'f1' , \"model\", \"split_percent\")\n",
    "    plot_results(plot_df, \"Split Percentage\", \"f1\",\n",
    "                         f'F1 score for {title}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "naughty-kitty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>split_percent</th>\n",
       "      <th>pretrain</th>\n",
       "      <th>architecture</th>\n",
       "      <th>loss</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "      <th>f1</th>\n",
       "      <th>f0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>supervised_pretrained</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.438497</td>\n",
       "      <td>1593.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>1727.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.816929</td>\n",
       "      <td>0.839747</td>\n",
       "      <td>0.783571</td>\n",
       "      <td>0.903257</td>\n",
       "      <td>0.810687</td>\n",
       "      <td>0.820148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>supervised_pretrained</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.759526</td>\n",
       "      <td>1162.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>1787.0</td>\n",
       "      <td>869.0</td>\n",
       "      <td>0.725640</td>\n",
       "      <td>0.825284</td>\n",
       "      <td>0.572132</td>\n",
       "      <td>0.851404</td>\n",
       "      <td>0.675778</td>\n",
       "      <td>0.719208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>supervised_pretrained</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>1.299277</td>\n",
       "      <td>1111.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>1753.0</td>\n",
       "      <td>922.0</td>\n",
       "      <td>0.704724</td>\n",
       "      <td>0.799856</td>\n",
       "      <td>0.546483</td>\n",
       "      <td>0.804429</td>\n",
       "      <td>0.649328</td>\n",
       "      <td>0.692787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>supervised_pretrained</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.524251</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>623.0</td>\n",
       "      <td>1409.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>0.789616</td>\n",
       "      <td>0.742881</td>\n",
       "      <td>0.885827</td>\n",
       "      <td>0.872730</td>\n",
       "      <td>0.808081</td>\n",
       "      <td>0.785112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>supervised_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.645926</td>\n",
       "      <td>1506.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>1586.0</td>\n",
       "      <td>526.0</td>\n",
       "      <td>0.760827</td>\n",
       "      <td>0.771516</td>\n",
       "      <td>0.741142</td>\n",
       "      <td>0.843999</td>\n",
       "      <td>0.756024</td>\n",
       "      <td>0.761119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>supervised_pretrained</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.457285</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>1746.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>0.790600</td>\n",
       "      <td>0.834471</td>\n",
       "      <td>0.723730</td>\n",
       "      <td>0.889169</td>\n",
       "      <td>0.775165</td>\n",
       "      <td>0.793974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  split_percent  pretrain architecture      loss  \\\n",
       "62  supervised_pretrained            100      True    ResNet152  0.438497   \n",
       "67  supervised_pretrained             10      True    ResNet152  0.759526   \n",
       "72  supervised_pretrained              1      True    ResNet152  1.299277   \n",
       "77  supervised_pretrained             25      True    ResNet152  0.524251   \n",
       "82  supervised_pretrained              3      True    ResNet152  0.645926   \n",
       "87  supervised_pretrained             50      True    ResNet152  0.457285   \n",
       "\n",
       "        tp     fp      tn     fn  accuracy  precision    recall       auc  \\\n",
       "62  1593.0  304.0  1727.0  440.0  0.816929   0.839747  0.783571  0.903257   \n",
       "67  1162.0  246.0  1787.0  869.0  0.725640   0.825284  0.572132  0.851404   \n",
       "72  1111.0  278.0  1753.0  922.0  0.704724   0.799856  0.546483  0.804429   \n",
       "77  1800.0  623.0  1409.0  232.0  0.789616   0.742881  0.885827  0.872730   \n",
       "82  1506.0  446.0  1586.0  526.0  0.760827   0.771516  0.741142  0.843999   \n",
       "87  1467.0  291.0  1746.0  560.0  0.790600   0.834471  0.723730  0.889169   \n",
       "\n",
       "          f1      f0.5  \n",
       "62  0.810687  0.820148  \n",
       "67  0.675778  0.719208  \n",
       "72  0.649328  0.692787  \n",
       "77  0.808081  0.785112  \n",
       "82  0.756024  0.761119  \n",
       "87  0.775165  0.793974  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# also get information for pretrained supervised\n",
    "_df3 = df2[(df2.model_type.isin(['supervised_baseline_pretrained'])) & \n",
    "           (df2.architecture == 'ResNet152') &\n",
    "           (df2.pretrain == True)]\n",
    "_df3 = _df3.rename(columns = {'model_type' : 'model'})\n",
    "_df3['model'] = 'supervised_pretrained'\n",
    "_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "contemporary-disaster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>split_percent</th>\n",
       "      <th>pretrain</th>\n",
       "      <th>architecture</th>\n",
       "      <th>loss</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "      <th>f1</th>\n",
       "      <th>f0.5</th>\n",
       "      <th>labeling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>supervised</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.243032</td>\n",
       "      <td>1926.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>1795.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.915600</td>\n",
       "      <td>0.891254</td>\n",
       "      <td>0.946903</td>\n",
       "      <td>0.951272</td>\n",
       "      <td>0.918236</td>\n",
       "      <td>0.909062</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>supervised</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.303365</td>\n",
       "      <td>1907.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.885581</td>\n",
       "      <td>0.848310</td>\n",
       "      <td>0.938946</td>\n",
       "      <td>0.939483</td>\n",
       "      <td>0.891330</td>\n",
       "      <td>0.876513</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>supervised</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.455079</td>\n",
       "      <td>1349.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>1809.0</td>\n",
       "      <td>685.0</td>\n",
       "      <td>0.777067</td>\n",
       "      <td>0.859236</td>\n",
       "      <td>0.663225</td>\n",
       "      <td>0.902077</td>\n",
       "      <td>0.748613</td>\n",
       "      <td>0.782180</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>supervised</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.274974</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>1668.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.907726</td>\n",
       "      <td>0.848447</td>\n",
       "      <td>0.993120</td>\n",
       "      <td>0.947509</td>\n",
       "      <td>0.915101</td>\n",
       "      <td>0.891749</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>supervised</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.439815</td>\n",
       "      <td>1425.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>1871.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>0.897921</td>\n",
       "      <td>0.701625</td>\n",
       "      <td>0.919590</td>\n",
       "      <td>0.787728</td>\n",
       "      <td>0.821326</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>supervised</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.193318</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.936516</td>\n",
       "      <td>0.904372</td>\n",
       "      <td>0.976401</td>\n",
       "      <td>0.964253</td>\n",
       "      <td>0.939007</td>\n",
       "      <td>0.927171</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BEN</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.394389</td>\n",
       "      <td>1889.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.828740</td>\n",
       "      <td>0.773230</td>\n",
       "      <td>0.930084</td>\n",
       "      <td>0.895239</td>\n",
       "      <td>0.844435</td>\n",
       "      <td>0.819286</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BEN</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.468172</td>\n",
       "      <td>1602.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>1560.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>0.778051</td>\n",
       "      <td>0.772420</td>\n",
       "      <td>0.788386</td>\n",
       "      <td>0.864622</td>\n",
       "      <td>0.780321</td>\n",
       "      <td>0.777670</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BEN</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.601744</td>\n",
       "      <td>1736.0</td>\n",
       "      <td>718.0</td>\n",
       "      <td>1313.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.750246</td>\n",
       "      <td>0.707416</td>\n",
       "      <td>0.853911</td>\n",
       "      <td>0.799443</td>\n",
       "      <td>0.773791</td>\n",
       "      <td>0.750324</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BEN</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.429256</td>\n",
       "      <td>1755.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1531.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>0.808563</td>\n",
       "      <td>0.778270</td>\n",
       "      <td>0.863256</td>\n",
       "      <td>0.880372</td>\n",
       "      <td>0.818563</td>\n",
       "      <td>0.804677</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BEN</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.414822</td>\n",
       "      <td>1773.0</td>\n",
       "      <td>538.0</td>\n",
       "      <td>1492.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>0.803396</td>\n",
       "      <td>0.767200</td>\n",
       "      <td>0.871681</td>\n",
       "      <td>0.882509</td>\n",
       "      <td>0.816110</td>\n",
       "      <td>0.799129</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BEN</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420994</td>\n",
       "      <td>1685.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>1618.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>0.812746</td>\n",
       "      <td>0.802763</td>\n",
       "      <td>0.829232</td>\n",
       "      <td>0.890809</td>\n",
       "      <td>0.815783</td>\n",
       "      <td>0.811396</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CA_sgd</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.399917</td>\n",
       "      <td>1887.0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.824065</td>\n",
       "      <td>0.768010</td>\n",
       "      <td>0.928642</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>0.840722</td>\n",
       "      <td>0.815001</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CA_sgd</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.493672</td>\n",
       "      <td>1699.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>1528.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>0.794045</td>\n",
       "      <td>0.771221</td>\n",
       "      <td>0.836122</td>\n",
       "      <td>0.861226</td>\n",
       "      <td>0.802361</td>\n",
       "      <td>0.791705</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CA_sgd</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.355194</td>\n",
       "      <td>1804.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>1608.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>0.839567</td>\n",
       "      <td>0.811151</td>\n",
       "      <td>0.886051</td>\n",
       "      <td>0.915509</td>\n",
       "      <td>0.846948</td>\n",
       "      <td>0.834670</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CA_sgd</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.397361</td>\n",
       "      <td>1899.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>1464.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.827510</td>\n",
       "      <td>0.770698</td>\n",
       "      <td>0.933170</td>\n",
       "      <td>0.898676</td>\n",
       "      <td>0.844188</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CA_sgd</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.432705</td>\n",
       "      <td>1691.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>1580.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>0.804872</td>\n",
       "      <td>0.788713</td>\n",
       "      <td>0.832595</td>\n",
       "      <td>0.880461</td>\n",
       "      <td>0.810060</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CA_sgd</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.370097</td>\n",
       "      <td>1735.0</td>\n",
       "      <td>381.0</td>\n",
       "      <td>1648.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.832431</td>\n",
       "      <td>0.819943</td>\n",
       "      <td>0.852580</td>\n",
       "      <td>0.910474</td>\n",
       "      <td>0.835943</td>\n",
       "      <td>0.830541</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CA_adam</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.189502</td>\n",
       "      <td>1799.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>1746.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0.872293</td>\n",
       "      <td>0.862830</td>\n",
       "      <td>0.885335</td>\n",
       "      <td>0.894910</td>\n",
       "      <td>0.873937</td>\n",
       "      <td>0.870203</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>CA_adam</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.069070</td>\n",
       "      <td>1787.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1646.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>0.844734</td>\n",
       "      <td>0.823123</td>\n",
       "      <td>0.878564</td>\n",
       "      <td>0.856991</td>\n",
       "      <td>0.849941</td>\n",
       "      <td>0.840809</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>CA_adam</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581498</td>\n",
       "      <td>1881.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>0.876969</td>\n",
       "      <td>0.844255</td>\n",
       "      <td>0.924779</td>\n",
       "      <td>0.902685</td>\n",
       "      <td>0.882684</td>\n",
       "      <td>0.869492</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>CA_adam</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.199074</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>603.0</td>\n",
       "      <td>1431.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>0.752461</td>\n",
       "      <td>0.729596</td>\n",
       "      <td>0.801478</td>\n",
       "      <td>0.754978</td>\n",
       "      <td>0.763850</td>\n",
       "      <td>0.752080</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CA_adam</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.830275</td>\n",
       "      <td>1679.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>1811.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>0.858760</td>\n",
       "      <td>0.883684</td>\n",
       "      <td>0.826280</td>\n",
       "      <td>0.917181</td>\n",
       "      <td>0.854018</td>\n",
       "      <td>0.863683</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>CA_adam</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.838003</td>\n",
       "      <td>1582.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>1669.0</td>\n",
       "      <td>451.0</td>\n",
       "      <td>0.799951</td>\n",
       "      <td>0.813786</td>\n",
       "      <td>0.778160</td>\n",
       "      <td>0.804820</td>\n",
       "      <td>0.795575</td>\n",
       "      <td>0.801554</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>supervised_pretrained</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.438497</td>\n",
       "      <td>1593.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>1727.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.816929</td>\n",
       "      <td>0.839747</td>\n",
       "      <td>0.783571</td>\n",
       "      <td>0.903257</td>\n",
       "      <td>0.810687</td>\n",
       "      <td>0.820148</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>supervised_pretrained</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.759526</td>\n",
       "      <td>1162.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>1787.0</td>\n",
       "      <td>869.0</td>\n",
       "      <td>0.725640</td>\n",
       "      <td>0.825284</td>\n",
       "      <td>0.572132</td>\n",
       "      <td>0.851404</td>\n",
       "      <td>0.675778</td>\n",
       "      <td>0.719208</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>supervised_pretrained</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>1.299277</td>\n",
       "      <td>1111.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>1753.0</td>\n",
       "      <td>922.0</td>\n",
       "      <td>0.704724</td>\n",
       "      <td>0.799856</td>\n",
       "      <td>0.546483</td>\n",
       "      <td>0.804429</td>\n",
       "      <td>0.649328</td>\n",
       "      <td>0.692787</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>supervised_pretrained</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.524251</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>623.0</td>\n",
       "      <td>1409.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>0.789616</td>\n",
       "      <td>0.742881</td>\n",
       "      <td>0.885827</td>\n",
       "      <td>0.872730</td>\n",
       "      <td>0.808081</td>\n",
       "      <td>0.785112</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>supervised_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.645926</td>\n",
       "      <td>1506.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>1586.0</td>\n",
       "      <td>526.0</td>\n",
       "      <td>0.760827</td>\n",
       "      <td>0.771516</td>\n",
       "      <td>0.741142</td>\n",
       "      <td>0.843999</td>\n",
       "      <td>0.756024</td>\n",
       "      <td>0.761119</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>supervised_pretrained</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.457285</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>1746.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>0.790600</td>\n",
       "      <td>0.834471</td>\n",
       "      <td>0.723730</td>\n",
       "      <td>0.889169</td>\n",
       "      <td>0.775165</td>\n",
       "      <td>0.793974</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  split_percent  pretrain architecture       loss  \\\n",
       "2              supervised            100     False    ResNet152   0.243032   \n",
       "7              supervised             10     False    ResNet152   0.303365   \n",
       "12             supervised              1     False    ResNet152   0.455079   \n",
       "17             supervised             25     False    ResNet152   0.274974   \n",
       "22             supervised              3     False    ResNet152   0.439815   \n",
       "27             supervised             50     False    ResNet152   0.193318   \n",
       "0                     BEN            100     False          NaN   0.394389   \n",
       "5                     BEN              3     False          NaN   0.468172   \n",
       "6                     BEN              1     False          NaN   0.601744   \n",
       "7                     BEN             25     False          NaN   0.429256   \n",
       "10                    BEN             10     False          NaN   0.414822   \n",
       "11                    BEN             50     False          NaN   0.420994   \n",
       "13                 CA_sgd             10     False          NaN   0.399917   \n",
       "14                 CA_sgd              1     False          NaN   0.493672   \n",
       "16                 CA_sgd            100     False          NaN   0.355194   \n",
       "18                 CA_sgd             25     False          NaN   0.397361   \n",
       "22                 CA_sgd              3     False          NaN   0.432705   \n",
       "23                 CA_sgd             50     False          NaN   0.370097   \n",
       "24                CA_adam             25     False          NaN   2.189502   \n",
       "26                CA_adam             10     False          NaN   6.069070   \n",
       "27                CA_adam             50     False          NaN   1.581498   \n",
       "28                CA_adam              1     False          NaN  43.199074   \n",
       "29                CA_adam            100     False          NaN   0.830275   \n",
       "32                CA_adam              3     False          NaN  18.838003   \n",
       "62  supervised_pretrained            100      True    ResNet152   0.438497   \n",
       "67  supervised_pretrained             10      True    ResNet152   0.759526   \n",
       "72  supervised_pretrained              1      True    ResNet152   1.299277   \n",
       "77  supervised_pretrained             25      True    ResNet152   0.524251   \n",
       "82  supervised_pretrained              3      True    ResNet152   0.645926   \n",
       "87  supervised_pretrained             50      True    ResNet152   0.457285   \n",
       "\n",
       "        tp     fp      tn     fn  accuracy  precision    recall       auc  \\\n",
       "2   1926.0  235.0  1795.0  108.0  0.915600   0.891254  0.946903  0.951272   \n",
       "7   1907.0  341.0  1692.0  124.0  0.885581   0.848310  0.938946  0.939483   \n",
       "12  1349.0  221.0  1809.0  685.0  0.777067   0.859236  0.663225  0.902077   \n",
       "17  2021.0  361.0  1668.0   14.0  0.907726   0.848447  0.993120  0.947509   \n",
       "22  1425.0  162.0  1871.0  606.0  0.811024   0.897921  0.701625  0.919590   \n",
       "27  1986.0  210.0  1820.0   48.0  0.936516   0.904372  0.976401  0.964253   \n",
       "0   1889.0  554.0  1479.0  142.0  0.828740   0.773230  0.930084  0.895239   \n",
       "5   1602.0  472.0  1560.0  430.0  0.778051   0.772420  0.788386  0.864622   \n",
       "6   1736.0  718.0  1313.0  297.0  0.750246   0.707416  0.853911  0.799443   \n",
       "7   1755.0  500.0  1531.0  278.0  0.808563   0.778270  0.863256  0.880372   \n",
       "10  1773.0  538.0  1492.0  261.0  0.803396   0.767200  0.871681  0.882509   \n",
       "11  1685.0  414.0  1618.0  347.0  0.812746   0.802763  0.829232  0.890809   \n",
       "13  1887.0  570.0  1462.0  145.0  0.824065   0.768010  0.928642  0.894000   \n",
       "14  1699.0  504.0  1528.0  333.0  0.794045   0.771221  0.836122  0.861226   \n",
       "16  1804.0  420.0  1608.0  232.0  0.839567   0.811151  0.886051  0.915509   \n",
       "18  1899.0  565.0  1464.0  136.0  0.827510   0.770698  0.933170  0.898676   \n",
       "22  1691.0  453.0  1580.0  340.0  0.804872   0.788713  0.832595  0.880461   \n",
       "23  1735.0  381.0  1648.0  300.0  0.832431   0.819943  0.852580  0.910474   \n",
       "24  1799.0  286.0  1746.0  233.0  0.872293   0.862830  0.885335  0.894910   \n",
       "26  1787.0  384.0  1646.0  247.0  0.844734   0.823123  0.878564  0.856991   \n",
       "27  1881.0  347.0  1683.0  153.0  0.876969   0.844255  0.924779  0.902685   \n",
       "28  1627.0  603.0  1431.0  403.0  0.752461   0.729596  0.801478  0.754978   \n",
       "29  1679.0  221.0  1811.0  353.0  0.858760   0.883684  0.826280  0.917181   \n",
       "32  1582.0  362.0  1669.0  451.0  0.799951   0.813786  0.778160  0.804820   \n",
       "62  1593.0  304.0  1727.0  440.0  0.816929   0.839747  0.783571  0.903257   \n",
       "67  1162.0  246.0  1787.0  869.0  0.725640   0.825284  0.572132  0.851404   \n",
       "72  1111.0  278.0  1753.0  922.0  0.704724   0.799856  0.546483  0.804429   \n",
       "77  1800.0  623.0  1409.0  232.0  0.789616   0.742881  0.885827  0.872730   \n",
       "82  1506.0  446.0  1586.0  526.0  0.760827   0.771516  0.741142  0.843999   \n",
       "87  1467.0  291.0  1746.0  560.0  0.790600   0.834471  0.723730  0.889169   \n",
       "\n",
       "          f1      f0.5  labeling  \n",
       "2   0.918236  0.909062       NaN  \n",
       "7   0.891330  0.876513       NaN  \n",
       "12  0.748613  0.782180       NaN  \n",
       "17  0.915101  0.891749       NaN  \n",
       "22  0.787728  0.821326       NaN  \n",
       "27  0.939007  0.927171       NaN  \n",
       "0   0.844435  0.819286  balanced  \n",
       "5   0.780321  0.777670  balanced  \n",
       "6   0.773791  0.750324  balanced  \n",
       "7   0.818563  0.804677  balanced  \n",
       "10  0.816110  0.799129  balanced  \n",
       "11  0.815783  0.811396  balanced  \n",
       "13  0.840722  0.815001  balanced  \n",
       "14  0.802361  0.791705  balanced  \n",
       "16  0.846948  0.834670  balanced  \n",
       "18  0.844188  0.818182  balanced  \n",
       "22  0.810060  0.802817  balanced  \n",
       "23  0.835943  0.830541  balanced  \n",
       "24  0.873937  0.870203  balanced  \n",
       "26  0.849941  0.840809  balanced  \n",
       "27  0.882684  0.869492  balanced  \n",
       "28  0.763850  0.752080  balanced  \n",
       "29  0.854018  0.863683  balanced  \n",
       "32  0.795575  0.801554  balanced  \n",
       "62  0.810687  0.820148       NaN  \n",
       "67  0.675778  0.719208       NaN  \n",
       "72  0.649328  0.692787       NaN  \n",
       "77  0.808081  0.785112       NaN  \n",
       "82  0.756024  0.761119       NaN  \n",
       "87  0.775165  0.793974       NaN  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the supervised dataset with the simclr results for common graphing\n",
    "new_data = pd.concat([_df2, _df, _df3])\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "shared-pharmaceutical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>split_percent</th>\n",
       "      <th>pretrain</th>\n",
       "      <th>architecture</th>\n",
       "      <th>loss</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "      <th>f1</th>\n",
       "      <th>f0.5</th>\n",
       "      <th>labeling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>supervised</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.243032</td>\n",
       "      <td>1926.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>1795.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.915600</td>\n",
       "      <td>0.891254</td>\n",
       "      <td>0.946903</td>\n",
       "      <td>0.951272</td>\n",
       "      <td>0.918236</td>\n",
       "      <td>0.909062</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>supervised</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.303365</td>\n",
       "      <td>1907.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.885581</td>\n",
       "      <td>0.848310</td>\n",
       "      <td>0.938946</td>\n",
       "      <td>0.939483</td>\n",
       "      <td>0.891330</td>\n",
       "      <td>0.876513</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>supervised</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.455079</td>\n",
       "      <td>1349.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>1809.0</td>\n",
       "      <td>685.0</td>\n",
       "      <td>0.777067</td>\n",
       "      <td>0.859236</td>\n",
       "      <td>0.663225</td>\n",
       "      <td>0.902077</td>\n",
       "      <td>0.748613</td>\n",
       "      <td>0.782180</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>supervised</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.274974</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>1668.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.907726</td>\n",
       "      <td>0.848447</td>\n",
       "      <td>0.993120</td>\n",
       "      <td>0.947509</td>\n",
       "      <td>0.915101</td>\n",
       "      <td>0.891749</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>supervised</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.439815</td>\n",
       "      <td>1425.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>1871.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>0.897921</td>\n",
       "      <td>0.701625</td>\n",
       "      <td>0.919590</td>\n",
       "      <td>0.787728</td>\n",
       "      <td>0.821326</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>supervised</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.193318</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.936516</td>\n",
       "      <td>0.904372</td>\n",
       "      <td>0.976401</td>\n",
       "      <td>0.964253</td>\n",
       "      <td>0.939007</td>\n",
       "      <td>0.927171</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BEN</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.394389</td>\n",
       "      <td>1889.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.828740</td>\n",
       "      <td>0.773230</td>\n",
       "      <td>0.930084</td>\n",
       "      <td>0.895239</td>\n",
       "      <td>0.844435</td>\n",
       "      <td>0.819286</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BEN</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.468172</td>\n",
       "      <td>1602.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>1560.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>0.778051</td>\n",
       "      <td>0.772420</td>\n",
       "      <td>0.788386</td>\n",
       "      <td>0.864622</td>\n",
       "      <td>0.780321</td>\n",
       "      <td>0.777670</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BEN</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.601744</td>\n",
       "      <td>1736.0</td>\n",
       "      <td>718.0</td>\n",
       "      <td>1313.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.750246</td>\n",
       "      <td>0.707416</td>\n",
       "      <td>0.853911</td>\n",
       "      <td>0.799443</td>\n",
       "      <td>0.773791</td>\n",
       "      <td>0.750324</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BEN</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.429256</td>\n",
       "      <td>1755.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1531.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>0.808563</td>\n",
       "      <td>0.778270</td>\n",
       "      <td>0.863256</td>\n",
       "      <td>0.880372</td>\n",
       "      <td>0.818563</td>\n",
       "      <td>0.804677</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BEN</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.414822</td>\n",
       "      <td>1773.0</td>\n",
       "      <td>538.0</td>\n",
       "      <td>1492.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>0.803396</td>\n",
       "      <td>0.767200</td>\n",
       "      <td>0.871681</td>\n",
       "      <td>0.882509</td>\n",
       "      <td>0.816110</td>\n",
       "      <td>0.799129</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BEN</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420994</td>\n",
       "      <td>1685.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>1618.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>0.812746</td>\n",
       "      <td>0.802763</td>\n",
       "      <td>0.829232</td>\n",
       "      <td>0.890809</td>\n",
       "      <td>0.815783</td>\n",
       "      <td>0.811396</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CA_sgd</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.399917</td>\n",
       "      <td>1887.0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.824065</td>\n",
       "      <td>0.768010</td>\n",
       "      <td>0.928642</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>0.840722</td>\n",
       "      <td>0.815001</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CA_sgd</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.493672</td>\n",
       "      <td>1699.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>1528.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>0.794045</td>\n",
       "      <td>0.771221</td>\n",
       "      <td>0.836122</td>\n",
       "      <td>0.861226</td>\n",
       "      <td>0.802361</td>\n",
       "      <td>0.791705</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CA_sgd</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.355194</td>\n",
       "      <td>1804.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>1608.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>0.839567</td>\n",
       "      <td>0.811151</td>\n",
       "      <td>0.886051</td>\n",
       "      <td>0.915509</td>\n",
       "      <td>0.846948</td>\n",
       "      <td>0.834670</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CA_sgd</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.397361</td>\n",
       "      <td>1899.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>1464.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.827510</td>\n",
       "      <td>0.770698</td>\n",
       "      <td>0.933170</td>\n",
       "      <td>0.898676</td>\n",
       "      <td>0.844188</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CA_sgd</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.432705</td>\n",
       "      <td>1691.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>1580.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>0.804872</td>\n",
       "      <td>0.788713</td>\n",
       "      <td>0.832595</td>\n",
       "      <td>0.880461</td>\n",
       "      <td>0.810060</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CA_sgd</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.370097</td>\n",
       "      <td>1735.0</td>\n",
       "      <td>381.0</td>\n",
       "      <td>1648.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.832431</td>\n",
       "      <td>0.819943</td>\n",
       "      <td>0.852580</td>\n",
       "      <td>0.910474</td>\n",
       "      <td>0.835943</td>\n",
       "      <td>0.830541</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CA_adam</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.189502</td>\n",
       "      <td>1799.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>1746.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0.872293</td>\n",
       "      <td>0.862830</td>\n",
       "      <td>0.885335</td>\n",
       "      <td>0.894910</td>\n",
       "      <td>0.873937</td>\n",
       "      <td>0.870203</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>CA_adam</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.069070</td>\n",
       "      <td>1787.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1646.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>0.844734</td>\n",
       "      <td>0.823123</td>\n",
       "      <td>0.878564</td>\n",
       "      <td>0.856991</td>\n",
       "      <td>0.849941</td>\n",
       "      <td>0.840809</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>CA_adam</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.581498</td>\n",
       "      <td>1881.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>0.876969</td>\n",
       "      <td>0.844255</td>\n",
       "      <td>0.924779</td>\n",
       "      <td>0.902685</td>\n",
       "      <td>0.882684</td>\n",
       "      <td>0.869492</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>CA_adam</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.199074</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>603.0</td>\n",
       "      <td>1431.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>0.752461</td>\n",
       "      <td>0.729596</td>\n",
       "      <td>0.801478</td>\n",
       "      <td>0.754978</td>\n",
       "      <td>0.763850</td>\n",
       "      <td>0.752080</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CA_adam</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.830275</td>\n",
       "      <td>1679.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>1811.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>0.858760</td>\n",
       "      <td>0.883684</td>\n",
       "      <td>0.826280</td>\n",
       "      <td>0.917181</td>\n",
       "      <td>0.854018</td>\n",
       "      <td>0.863683</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>CA_adam</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.838003</td>\n",
       "      <td>1582.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>1669.0</td>\n",
       "      <td>451.0</td>\n",
       "      <td>0.799951</td>\n",
       "      <td>0.813786</td>\n",
       "      <td>0.778160</td>\n",
       "      <td>0.804820</td>\n",
       "      <td>0.795575</td>\n",
       "      <td>0.801554</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>supervised_pretrained</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.438497</td>\n",
       "      <td>1593.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>1727.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.816929</td>\n",
       "      <td>0.839747</td>\n",
       "      <td>0.783571</td>\n",
       "      <td>0.903257</td>\n",
       "      <td>0.810687</td>\n",
       "      <td>0.820148</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>supervised_pretrained</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.759526</td>\n",
       "      <td>1162.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>1787.0</td>\n",
       "      <td>869.0</td>\n",
       "      <td>0.725640</td>\n",
       "      <td>0.825284</td>\n",
       "      <td>0.572132</td>\n",
       "      <td>0.851404</td>\n",
       "      <td>0.675778</td>\n",
       "      <td>0.719208</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>supervised_pretrained</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>1.299277</td>\n",
       "      <td>1111.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>1753.0</td>\n",
       "      <td>922.0</td>\n",
       "      <td>0.704724</td>\n",
       "      <td>0.799856</td>\n",
       "      <td>0.546483</td>\n",
       "      <td>0.804429</td>\n",
       "      <td>0.649328</td>\n",
       "      <td>0.692787</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>supervised_pretrained</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.524251</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>623.0</td>\n",
       "      <td>1409.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>0.789616</td>\n",
       "      <td>0.742881</td>\n",
       "      <td>0.885827</td>\n",
       "      <td>0.872730</td>\n",
       "      <td>0.808081</td>\n",
       "      <td>0.785112</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>supervised_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.645926</td>\n",
       "      <td>1506.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>1586.0</td>\n",
       "      <td>526.0</td>\n",
       "      <td>0.760827</td>\n",
       "      <td>0.771516</td>\n",
       "      <td>0.741142</td>\n",
       "      <td>0.843999</td>\n",
       "      <td>0.756024</td>\n",
       "      <td>0.761119</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>supervised_pretrained</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>ResNet152</td>\n",
       "      <td>0.457285</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>1746.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>0.790600</td>\n",
       "      <td>0.834471</td>\n",
       "      <td>0.723730</td>\n",
       "      <td>0.889169</td>\n",
       "      <td>0.775165</td>\n",
       "      <td>0.793974</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  split_percent  pretrain architecture       loss  \\\n",
       "2              supervised            100     False    ResNet152   0.243032   \n",
       "7              supervised             10     False    ResNet152   0.303365   \n",
       "12             supervised              1     False    ResNet152   0.455079   \n",
       "17             supervised             25     False    ResNet152   0.274974   \n",
       "22             supervised              3     False    ResNet152   0.439815   \n",
       "27             supervised             50     False    ResNet152   0.193318   \n",
       "0                     BEN            100     False          NaN   0.394389   \n",
       "5                     BEN              3     False          NaN   0.468172   \n",
       "6                     BEN              1     False          NaN   0.601744   \n",
       "7                     BEN             25     False          NaN   0.429256   \n",
       "10                    BEN             10     False          NaN   0.414822   \n",
       "11                    BEN             50     False          NaN   0.420994   \n",
       "13                 CA_sgd             10     False          NaN   0.399917   \n",
       "14                 CA_sgd              1     False          NaN   0.493672   \n",
       "16                 CA_sgd            100     False          NaN   0.355194   \n",
       "18                 CA_sgd             25     False          NaN   0.397361   \n",
       "22                 CA_sgd              3     False          NaN   0.432705   \n",
       "23                 CA_sgd             50     False          NaN   0.370097   \n",
       "24                CA_adam             25     False          NaN   2.189502   \n",
       "26                CA_adam             10     False          NaN   6.069070   \n",
       "27                CA_adam             50     False          NaN   1.581498   \n",
       "28                CA_adam              1     False          NaN  43.199074   \n",
       "29                CA_adam            100     False          NaN   0.830275   \n",
       "32                CA_adam              3     False          NaN  18.838003   \n",
       "62  supervised_pretrained            100      True    ResNet152   0.438497   \n",
       "67  supervised_pretrained             10      True    ResNet152   0.759526   \n",
       "72  supervised_pretrained              1      True    ResNet152   1.299277   \n",
       "77  supervised_pretrained             25      True    ResNet152   0.524251   \n",
       "82  supervised_pretrained              3      True    ResNet152   0.645926   \n",
       "87  supervised_pretrained             50      True    ResNet152   0.457285   \n",
       "\n",
       "        tp     fp      tn     fn  accuracy  precision    recall       auc  \\\n",
       "2   1926.0  235.0  1795.0  108.0  0.915600   0.891254  0.946903  0.951272   \n",
       "7   1907.0  341.0  1692.0  124.0  0.885581   0.848310  0.938946  0.939483   \n",
       "12  1349.0  221.0  1809.0  685.0  0.777067   0.859236  0.663225  0.902077   \n",
       "17  2021.0  361.0  1668.0   14.0  0.907726   0.848447  0.993120  0.947509   \n",
       "22  1425.0  162.0  1871.0  606.0  0.811024   0.897921  0.701625  0.919590   \n",
       "27  1986.0  210.0  1820.0   48.0  0.936516   0.904372  0.976401  0.964253   \n",
       "0   1889.0  554.0  1479.0  142.0  0.828740   0.773230  0.930084  0.895239   \n",
       "5   1602.0  472.0  1560.0  430.0  0.778051   0.772420  0.788386  0.864622   \n",
       "6   1736.0  718.0  1313.0  297.0  0.750246   0.707416  0.853911  0.799443   \n",
       "7   1755.0  500.0  1531.0  278.0  0.808563   0.778270  0.863256  0.880372   \n",
       "10  1773.0  538.0  1492.0  261.0  0.803396   0.767200  0.871681  0.882509   \n",
       "11  1685.0  414.0  1618.0  347.0  0.812746   0.802763  0.829232  0.890809   \n",
       "13  1887.0  570.0  1462.0  145.0  0.824065   0.768010  0.928642  0.894000   \n",
       "14  1699.0  504.0  1528.0  333.0  0.794045   0.771221  0.836122  0.861226   \n",
       "16  1804.0  420.0  1608.0  232.0  0.839567   0.811151  0.886051  0.915509   \n",
       "18  1899.0  565.0  1464.0  136.0  0.827510   0.770698  0.933170  0.898676   \n",
       "22  1691.0  453.0  1580.0  340.0  0.804872   0.788713  0.832595  0.880461   \n",
       "23  1735.0  381.0  1648.0  300.0  0.832431   0.819943  0.852580  0.910474   \n",
       "24  1799.0  286.0  1746.0  233.0  0.872293   0.862830  0.885335  0.894910   \n",
       "26  1787.0  384.0  1646.0  247.0  0.844734   0.823123  0.878564  0.856991   \n",
       "27  1881.0  347.0  1683.0  153.0  0.876969   0.844255  0.924779  0.902685   \n",
       "28  1627.0  603.0  1431.0  403.0  0.752461   0.729596  0.801478  0.754978   \n",
       "29  1679.0  221.0  1811.0  353.0  0.858760   0.883684  0.826280  0.917181   \n",
       "32  1582.0  362.0  1669.0  451.0  0.799951   0.813786  0.778160  0.804820   \n",
       "62  1593.0  304.0  1727.0  440.0  0.816929   0.839747  0.783571  0.903257   \n",
       "67  1162.0  246.0  1787.0  869.0  0.725640   0.825284  0.572132  0.851404   \n",
       "72  1111.0  278.0  1753.0  922.0  0.704724   0.799856  0.546483  0.804429   \n",
       "77  1800.0  623.0  1409.0  232.0  0.789616   0.742881  0.885827  0.872730   \n",
       "82  1506.0  446.0  1586.0  526.0  0.760827   0.771516  0.741142  0.843999   \n",
       "87  1467.0  291.0  1746.0  560.0  0.790600   0.834471  0.723730  0.889169   \n",
       "\n",
       "          f1      f0.5  labeling  \n",
       "2   0.918236  0.909062       NaN  \n",
       "7   0.891330  0.876513       NaN  \n",
       "12  0.748613  0.782180       NaN  \n",
       "17  0.915101  0.891749       NaN  \n",
       "22  0.787728  0.821326       NaN  \n",
       "27  0.939007  0.927171       NaN  \n",
       "0   0.844435  0.819286  balanced  \n",
       "5   0.780321  0.777670  balanced  \n",
       "6   0.773791  0.750324  balanced  \n",
       "7   0.818563  0.804677  balanced  \n",
       "10  0.816110  0.799129  balanced  \n",
       "11  0.815783  0.811396  balanced  \n",
       "13  0.840722  0.815001  balanced  \n",
       "14  0.802361  0.791705  balanced  \n",
       "16  0.846948  0.834670  balanced  \n",
       "18  0.844188  0.818182  balanced  \n",
       "22  0.810060  0.802817  balanced  \n",
       "23  0.835943  0.830541  balanced  \n",
       "24  0.873937  0.870203  balanced  \n",
       "26  0.849941  0.840809  balanced  \n",
       "27  0.882684  0.869492  balanced  \n",
       "28  0.763850  0.752080  balanced  \n",
       "29  0.854018  0.863683  balanced  \n",
       "32  0.795575  0.801554  balanced  \n",
       "62  0.810687  0.820148       NaN  \n",
       "67  0.675778  0.719208       NaN  \n",
       "72  0.649328  0.692787       NaN  \n",
       "77  0.808081  0.785112       NaN  \n",
       "82  0.756024  0.761119       NaN  \n",
       "87  0.775165  0.793974       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEdCAYAAAABymAfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deZgU1bnH8e+PAYMLoiBu7CoXMC4oBKNRgxi5qDGCGsUlQVFxiXuMS0wiuUbFqEnEDXHDuIGoGDRE3EBFEEEFERBDEGVcERX3sL33j67BnpmeoYGpaWb693meeag6darqreqm3q5TVacUEZiZWfFqUOgAzMyssJwIzMyKnBOBmVmRcyIwMytyTgRmZkXOicDMrMg5EaxnJPWVFJI6FTqWtSHpLElzJN27lvP3kPRYDcRxqqRfrkH9L1czvZ2k19cwhuGSjkiGb5O045rMX81y12kf51hezjgl/TxZz/hk/H5Jr0k6tybWW008v62h5Rwv6YZkeNX3ISnftibWUV80LHQAVsnRwESgHzAorZVIKomIFSks+nTgwIh4K884GkbE8poOIiKG1vQy10VEnFSDi0ttH1eI80Tg9IgYL2lrYK+IaJtvkOvw2f4WuGIt5qtShe/D8cDrwHs1uY66zGcE6xFJmwA/IvMfsF+FaRdImilphqTBSdkOkp5Kyl6RtH3FX9SSbpB0fDK8QNIfJE0Efi7pZElTk/kfkrRRUm8rSaOT8hmS9pJ0maSzs5Z7uaSzKsQ4FNgOGCPpXEnNJD2S/Ip8UdIuSb1BkoZJegL4e45dsWmy/tmShkpqkMx3s6RpkmZJ+mPWegcndV+TdE3WOs6vaj9V9xlIejqpN1PSoVmTG0q6K1nPg1n7q6ukZyW9LGmcpG1yLHeCpG7J8JfJ/puR7JetkvLtk/Gpkv4v11lKTexjZdyQ7LN/AltWjFPSH4C9gaGSrgaeALaUNF3SPkmsjyfb/LySM1hlzi7+osxZxFWSNpZ0R7JNr5btT2V+lT+cLOPfkv5c9lkCGybrubdC3CXJ8l9PPptzs2L+m6RJybTuOfbbIEnnK3Pm0w24N1nHhrm+P0UnIvy3nvwBxwG3J8OTgN2T4QOT8Y2S8WbJv1OAvslwY2AjoAfwWNYybwCOT4YXABdkTWueNfwn4MxkeCRwTjJcAjQF2gGvJGUNgP9kz5+1nAXAFsnw9cClyXBPYHoyPAh4Gdgwx/w9gG/JHOxKgCeBIypsdwkwAdgFaAbMBZRM2yxrHedXtZ9yrPfL5N+GwKbJ8BbAPEDJ9gfwo2TaHcD5QKPks2mRlB8F3JEMD8+KfQLQLRkO4JBk+M/A75Lhx4Cjk+FTy2JKYR8fluzXEmBb4LMq4swebge8nrWMp4EOyfAewDNZ2/wYUJKMXwEcV/bZAG8CG5P5VT6fzHerMfA20Dr7s8gRd1fgyazxzbLivDUZ3rcszmQdN+T4PmRvV87vT7H9+Yxg/XI0MCIZHpGMA/wEuDMivgaIiE8kNQFaRsTopOzbsumrMTJreKfk19xM4Fjg+0l5T+DmZLkrImJJRCwAFkvaDegFvBoRi1ezrr2Bu5PlPAM0l9Q0mTYmIr6pYr6XImJ+ZJqu7k+WA3CkpFeAV5NYdwQ+J5M4bpN0GFBuH6zFfhJwhaTXgKeAlsBWybSFEfFCMnxPEldHYCfgSUnTgd8BrarbKcBSMgdLyBys2yXDewKjkuH7VrOMMmuzj/cF7k8+2/eAZ/JcF7DqzHUvYFSyzbcA2WdBo+K7ZsdewEVJvQlkDvptkmlPJ9+tb4HZwOqaneYD20m6XlJvMp99mfsBIuI5MmeUm+W5OdV+f4qFrxGsJyQ1J3MA3klSkPm1FpIuIHNwqtgplKpY1HLKN/k1rjD9q6zh4UCfiJihTPNRj9WEeRuZX1lbk/lFvDq5Yizbjq9yTKtYZ9W4pPZkfoH/ICI+lTQcaBwRy5OmgP3JNKedQWY/VhdDdY4FWgBdI2KZpAV8tw8rxZUsf1ZE7LkG61gWyc9PYAXr9v+wpvbxmmgAfBYRXaqYnr1eAYdHxNzsCpL2AP6bVbTa/ZB87rsC/wv8CjgSGFA2uWL1arfgu2Wu7vtTFHxGsP44Avh7RLSNiHYR0Rp4i8wvvieAAVlt0s0i4nOgVFKfpOx7yfS3gR2T8aZkvuBVaQK8L6kRmQNgmaeB05LllkjaNCkfDfQGfgCMy2ObnitbrqQewMdJ3KvTXVJ7Za4NHEXm4vmmZA4wS5I29QOT5W4CNI2IscA5QLmDUzX7qSpNgY+SJLAf5X+ltpFUdsAvu6g/F2hRVi6pkaTvs3ZeBA5PhvtVVzHL2uzj54B+yWe7DbDfmgSZLP8tST9P1qvkAJ3LOOBMSUrq7pbHKpYl38lyJG0BNIiIh4DfA7tnTT4qqbM3sCQillSz/C/IfPdX+/0pFk4E64+jyRxosz0EHBMRjwNjgGnJKfb5yfRfAGclzRiTgK0jYiHwAPAacC+ZZpSq/J5M+/mTwBtZ5WcD+yVNRi+TNBlFxFJgPPBA5HfH0SCgWxLfYKB/HvMATE7qv04mGY6OiBnJtswiczZS1kTTBHgsWcezQK5bGyvtp2rWfW8S8zQyB9js/TIH6J8spxlwc7JPjiBzYXQGMJ1Ms8naOAc4T9JLZJpaqjuYlRnEmu/j0cC/gZlkmgCfXYtYjwVOTLZ5FnBoFfUuI3Md5TVlbr+9LI9lD0vqV7w9tiUwIfk/MBy4OGvap5ImAUPJ3GxRneFkLoJPJ7/vT72n785QzaqX/EJ/Bfh5RPy70PHUN8mZyjcREZL6kblwXNUB1hKSJpC5EDyt0LHUVb5GYHlR5iGjx8j8OncSSEdX4IakGeUzvmv/NktVamcEku4AfkqmvXWnHNMFXAccROZK/fER8UoqwZiZWZXSvEYwnMyFxaocCHRI/gaS3K5oZma1K7VEkNzP+0k1VQ4lc5dMRMSLwGbK8USmmZmlq5DXCFoCC7PGS5Oy9ytWlDSQzFkDG2+8cddOnepkf2xmZgXz8ssvfxwRLXJNK2QiqO5BmPKFEcPI3FJGt27dYto03xxgZrYmJL1d1bRCPkdQCrTOGm+FewM0M6t1hUwEY4BfJk8l/pDM04CVmoXMzCxdqTUNSbqfTN81W0gqBS4l84QhkekbfCyZW0fnkbl99IS0YjEzs6qllggi4ujVTA8yHUeZmVkBua8hM7Mi50RgZlbknAjMzIqcE4GZWZFzIjAzK3JOBGZmRc6JwMysyDkRmJkVOScCM7Mi50RgZlbknAjMzIqcE4GZWZFzIjAzK3JOBGZmRc6JwMysyDkRmJkVOScCM7Mil9obyszMasqcTp1zlnd+Y04tR1I/+YzAzKzIORGYmRU5JwIzsyLnRGBmVuScCMzMipwTgZlZkXMiMDMrcn6OwMyswHI9J1Gbz0j4jMDMrMilmggk9ZY0V9I8SRflmL65pNGSXpP0kqSd0ozHzMwqS61pSFIJcCNwAFAKTJU0JiJmZ1X7LTA9IvpK6pTU3z+tmMzqK3fBYOsizTOC7sC8iJgfEUuBEcChFersCDwNEBFvAO0kbZViTGZmVkGaiaAlsDBrvDQpyzYDOAxAUnegLdCq4oIkDZQ0TdK0RYsWpRSumVlxSjMRKEdZVBgfDGwuaTpwJvAqsLzSTBHDIqJbRHRr0aJFzUdqZlbE0rx9tBRonTXeCngvu0JEfA6cACBJwFvJn5mZ1ZI0zwimAh0ktZe0AdAPGJNdQdJmyTSAk4DnkuRgZma1JLUzgohYLukMYBxQAtwREbMknZpMHwp0Bv4uaQUwGzgxrXjMzCy3VJ8sjoixwNgKZUOzhicDHdKMwczMqucuJqwo+D57s6q5iwkzsyLnRGBmVuTcNGRmhTGoaRXlS2o3DvMZgZlZsfMZgdn6yr+YrZb4jMDMrMg5EZiZFTknAjOzIudrBGZmach1jWc9vb7jMwIzsyLnRGBmVuScCMzMipwTgZlZkXMiMDMrcr5ryOouP3lrViOcCMzMasnOd+2cs/yBWo6jIjcNmZkVOScCM7Mi56YhM1uv5Go+KXTTSX3nRGBmtg7aXfTPnOULGtdyIOvAicCsjvEvZqtpTgRW7/hAabZmfLHYzKzIORGYmRU5Nw2Zma2Hbjz1mZzlvxras8bX5URgZqmqD3fV1HdOBLbKnE6dK5V1fmNOASIxs9qUaiKQ1Bu4DigBbouIwRWmNwXuAdoksVwTEXemGZPZ+ijXr2b/YrbakloikFQC3AgcAJQCUyWNiYjZWdV+BcyOiEMktQDmSro3IpamFZetvx1fVccHSrP0pHnXUHdgXkTMTw7sI4BDK9QJoIkkAZsAnwDLU4zJzMwqSLNpqCWwMGu8FNijQp0bgDHAe0AT4KiIWFlxQZIGAgMB2rRpk0qw9VauPvvbex+a2XfSPCNQjrKoMP6/wHRgW6ALcIOkTSvNFDEsIrpFRLcWLVrUfKRmZkUszTOCUqB11ngrMr/8s50ADI6IAOZJegvoBLyUYlyrVVUb+sz+M2s5EjOz9KWZCKYCHSS1B94F+gHHVKjzDrA/8LykrYCOwPwUYzIrKrkeSkrjgaRCqe/bV1tSSwQRsVzSGcA4MreP3hERsySdmkwfClwGDJc0k0xT0oUR8XFaMZmZWWWpPkcQEWOBsRXKhmYNvwf0SjMGMzOrnjudMzMrck4EZmZFzn0NrYH1uS8ed+xlZmvLZwRmZkXOicDMrMg5EZiZFTknAjOzIudEYGZW5HzXkFWrNt+bamaF4TMCM7Mil1cikPSQpIMlOXGYmdUz+TYN3Uymy+ghkkYBwyPijfTCqkV+cYuZFbm8EkFEPAU8lbxs/mjgSUkLgVuBeyJiWYox1gg/eWtmllveTT2SmgPHAycBrwLXAbsDT6YSmZmZ1Yq8zggkPUzmzWF3A4dExPvJpJGSpqUVnJmZpS/fawQ3RETO+wgjolsNxmNmZrUs36ahzpI2KxuRtLmk01OKyczMalG+ieDkiPisbCQiPgVOTickMzOrTfkmggaSVDYiqQTYIJ2QzMysNuV7jWAc8ICkoUAApwKPpxaVmZnVmnwTwYXAKcBpgIAngNvSCsrMzGpPvg+UrSTzdPHN6YZjVrvcqZ5Z/s8RdACuBHYEVj2LGxHbpRSXmZnVknwvFt9J5mxgObAf8HcyD5eZmVkdl28i2DAingYUEW9HxCDA585mZvVAvheLv026oP63pDOAd4Et0wvLzMxqS75nBOcAGwFnAV2B44D+aQVlZma1Z7WJIHl47MiI+DIiSiPihIg4PCJezGPe3pLmSpon6aIc038jaXry97qkFZKareW2mJnZWlht01BErJDUVZIiIvJdcJJAbgQOAEqBqZLGRMTsrGVfDVyd1D8EODciPlnTjSgk335oZnVdvtcIXgX+kbyd7Kuywoh4uJp5ugPzImI+gKQRwKHA7CrqHw3cn2c8ZmZWQ/JNBM2AxZS/UyiA6hJBS2Bh1ngpsEeuipI2AnoDZ1QxfSAwEKBNG79G0sysJuX7ZPEJa7Fs5SirqmnpEOCFqpqFImIYMAygW7dueTdPmZnZ6uX7ZPGd5DiIR8SAamYrBVpnjbcC3quibj/cLGRmVhD5Ng09ljXcGOhL1Qf1MlOBDpLak3nuoB9wTMVKkpoCPyZzS6qZmdWyfJuGHsoel3Q/8NRq5lmePHw2DigB7oiIWZJOTaYPTar2BZ6IiK+qWJSZmaUo3zOCijoAq71qGxFjgbEVyoZWGB8ODF/LOMzMbB3le43gC8pfI/iAzDsKzMysjsu3aahJ2oGYmVlh5NXXkKS+yUXdsvHNJPVJLywzM6st+XY6d2lELCkbiYjPgEvTCcnMzGpTvokgV721vdBsZmbrkXwTwTRJf5G0vaTtJP0VeDnNwMzMrHbkmwjOBJYCI4EHgG+AX6UVlJmZ1Z587xr6Cqj0PgEzM6v78r1r6ElJm2WNby5pXHphmZlZbcm3aWiL5E4hACLiU/zOYjOzeiHfRLBS0qouJSS1o+oupc3MrA7J9xbQS4CJkp5NxvcleVGMmZnVbfleLH5cUjcyB//pwD/I3DlkZmZ1XL6dzp0EnE3m5TLTgR8Ckyn/6kozM6uD8r1GcDbwA+DtiNgP2A1YlFpUZmZWa/JNBN9GxLcAkr4XEW8AHdMLy8zMaku+F4tLk+cIHgGelPQpq39VpZmZ1QH5XizumwwOkjQeaAo8nlpUZmZWa9a4B9GIeHb1tczMrK7I9xqBmZnVU04EZmZFzonAzKzIORGYmRU5JwIzsyLnRGBmVuScCMzMipwTgZlZkUs1EUjqLWmupHmScr7zWFIPSdMlzcp634GZmdWSNX6yOF+SSoAbgQOAUmCqpDERMTurzmbATUDviHhHkl9/aWZWy9I8I+gOzIuI+RGxFBgBHFqhzjHAwxHxDkBEfJRiPGZmlkOaiaAlsDBrvDQpy/Y/wOaSJkh6WdIvcy1I0kBJ0yRNW7TIr0EwM6tJqTUNAcpRVvGF9w2BrsD+wIbAZEkvRsSb5WaKGAYMA+jWrVvFZZjZWlq2bBmlpaV8++23qa3j1p9tk7N8jh7IWf63hpUPS8tuzL3sH3xv88rLnTMn/+BqwJpsX65tg9zbl2vbIL/ta9y4Ma1ataJRo0arrQvpJoJSoHXWeCsqv8OgFPg4Ir4CvpL0HLAr8CZmlrrS0lKaNGlCu3btkHL9dlt3y0o/y1neuUHu9a3cYINKZdt9kPv33xdN2lQq27LtpmsQ3bpbk+3LtW2Qe/tybRusfvsigsWLF1NaWkr79u2rrVsmzaahqUAHSe0lbQD0A8ZUqPMPYB9JDSVtBOwB1G46Nyti3377Lc2bN08tCVjtk0Tz5s3X6CwvtTOCiFgu6QxgHFAC3BERsySdmkwfGhFzJD0OvAasBG6LiNfTisnMKnMSqH/W9DNNs2mIiBgLjK1QNrTC+NXA1WnGYWaFNXXyRH5/7mm0bN2W5cuXcemfh3DWJb8iIpBEs8025eHbrqXHESfTac9unHnxmbz7zrsMuXIIV918VaHDr/dSTQRmVne0u+if6zT/gsEHVzv9p4cdxRkX/I7p06Yw6p47AXh65FAaVriAOm3SNP777X/XKRZbM+5iwsxq1VdffMHGmzSpcvpBhx/Eo6MercWIzGcEZlYrHnt4JC9PmcQ7C+Yz9J6HeHPqePY/6lQksWOH7bjpyosBOOSIQzj92NPZ88d7Fjji4uFEYGa1oqxpaPGijxh0wVmI3E1DGzTegN332J1JEyYVJtAi5KYhM6tVG22yCV998UW1dY4ecDQj7hhRSxGZzwjMDFj9xd519djDI3l16ov897//5eSzfs1Dw65Z1TRU0qABTz9wy6q6LbZuwQ6dd0g1HvuOE4GZpe4He+7N4y/OLFd2Zq+OlepNePBWZiVNRb5ttPa4acjMrMg5EZiZFTknAjOzIudEYGZW5JwIzMyKnBOBmVmR8+2jZpYxqOk6zr+k2slTJj7LLX/7MxFB082bMeqaXzP73/M55Phz+GjG02ywQX5v08r2wuTnmfTiRH5z7sVrG7XhRGBmteDTTxZzy9/+zPXDR7DxJk1YMH8eS5d9wsNjn+GIg3/C0xNf4sCePyp0mEXLTUNmlrrnn36Cnx5+1KpeR9tttwPbbNWCN+e/w6XnDuSRx8fnnG/ZsmWceNiJHNC/P0efey4rVqwA4JTf/56DTzqJUaO/64bi5F/1p8+RB9GrVy8+//xzALp06cLxxx/PzjvvzOjRozn44IPp2rUrpaWlKW9x3eJEYGapW/TRB2yx5Vblyl6ZOYduu3amdcut+fDjT1i5cmWl+Ro2bMiN997Ik3fdRcf27ZkwZQpTZ86kpKSEf952G+3afvdO3uuuuZlHHhjLkUceyciRIwF4//33GTp0KLfccguXXXYZjz76KL/+9a954IHKL5YvZm4aMrPUtdhyaxZ9+EG5sofHPsOEyS8z5dXXebv0fSZNm8He3XcrV+ebr75h0K8H8fnbH/LR4sXs0LYtnyxZwq6dOgGw605dmPbKVFasWMH/XfF75sydzTf//Yq+ffsCsMMOO9C4cWO23XZbOnfuTIMGDdh2222ZM8evRs/mRGBmGau52Lsu9u55AOef0p/ePzuMjTdpwjtvzWfqjFlMfOQOAN6Y9xa33ju6UiJ4YfwLtN2+Ldf+8SouHTKEiKBty5Y8+9JLAMyc9RoAr89+ja+//pp/PPAv/vHESN59912g/Lt7s4cjIrVtrYucCMwsdc2ab8HAs3/Dmcf3IyLYcKON2LzRd3cJddqhPZNffq3SfDt33Zlhfx3GYVNm0XSTTdihTRu677ILt40cyUEnncTWbTrQattW7LBdB956ez79fnkY2/9Pe1q2bFmbm1fnORGYWa344T49+OE+PVaN79LgrXLTJ40ZXmmerbfdmlHPjGK7D8r/gh92+eUAfNGkzaqyRx8cB8CWbTddVTZx4kQA2rVrxz333ANAjx496NHjuzjMicDM1iMHHncGH/936arxS6+9lPY7tK9mDqsJTgRmtt741z03MGuDDQodRtHx7aNmZkXOicDMrMg5EZhZrZgy8VkGHHEwJxx+EOecdByLP/mM56e8wmad92Xp0mU1th5fCF5zvkZgZgDsfNfO6zT/zP4zq5zmvobWb6meEUjqLWmupHmSLsoxvYekJZKmJ39/SDMeMyuMte1r6J3573DsQcfSe8AA/nzrrQAMGjKEA/r357wrruCsX58GwN/vu5MD++zPZYMvrZ0NqmdSOyOQVALcCBwAlAJTJY2JiNkVqj4fET9NKw4zK7xFH31Ah047livL1ddQgwblf5u+9MJL/PwXP+e8/Q4lInh/0SKmz5nDk3fdxYOPP84/X3yV5cuXc9/Iu3nsoSd4dcbLzJzzam1uWr2Q5hlBd2BeRMyPiKXACODQFNdnZuupqvoaenriVHof+yvm/mcBk6bNqDRf7z69eXP2m5xw4YU8MXEiC997j+936ADALh07AvDJJ4tp3ao1DRs2ZJeduqS/MfVQmomgJbAwa7w0KatoT0kzJP1L0vdzLUjSQEnTJE1btGhRGrGaWYr27nkA/3z4Ab768guAcn0NPX7vjYy+/VpG/6ty81DDhg254LILuOVPf+KyG2+k9bbbMuc//wHg9TffBKBZs+YsLF3IihUrVvU9ZGsmzYvFylFWsaenV4C2EfGlpIOAR4AOlWaKGAYMA+jWrZt7izJLQXUXe9fV2vY1NP7x8dx/+/2s/Pwbjv7pT9mmRQt26diRn/TvT6fttqNho41o2LAhR//8WA4+7AD2+qEvOK+NNBNBKdA6a7wV8F52hYj4PGt4rKSbJG0RER+nGJeZFcDa9DV0YN8DObDvgeX6Gvrd6afTsGFDHnz8cd74KHOG0f+4E+l/3IlA+b6GLD9pJoKpQAdJ7YF3gX7AMdkVJG0NfBgRIak7maaqxSnGZGbrsXz6Gho0ZAhTZsygpKSEm4eOqLgIWwupJYKIWC7pDGAcUALcERGzJJ2aTB8KHAGcJmk58A3QL9xRuFnRyqevoT+dd96q4S+abJF2SEUh1QfKImIsMLZC2dCs4RuAG9KMwczMqucuJszMipwTgZlZkXMiMLN65cwzz1yr+Y4//ngWLFhQs8HUEe50zswAmNOp8zrN3/mNOTUUSX5WrlyZs/z666+v1TjqAycCM0vd9GlTuPqPl7DhRhtxcN8jefedBQy76FiGjxwDQI+9unHCuYPYtMnGLFj8KX++5c+0atuKB+9+kDEjx9B4GVx94YXstuOO7HH44Xy/Qwe2b9uW51+bzah7/gHA4cccwoi7Hmbvvfdm4sSJ/Pa3v+XZZ59lgw024N5776VRo0aceOKJfPHFF3Tu3JmbbrqJt956i6OPPpqtt96aL7/8spC7qKCcCMwsdROfeZJzfjuIH+y5Ny9Nep5331lQqc4Hiz7myRE3MWrOPG6//nbOuvgsJoybwF2P3sXmby7h1N//ngeGDOHdDz/kmbvvZuONNuLYS/5I6bsLWblyJS23aUWjrKeVX3jhBZ5//nkaNGhARHD++edz8cUXs+eee3LhhRcyefJk7r77bq699lr22GMPdt1111rcI+sXJwIzS92RvzyRW4dcw+gRd3NYv1+uKg8CJb3R7NypAw0bNqTTTp1Y+NZCSt8uZe6suZzQ5wQ2/O4ZMzq0a8fGG20EwE8P/BmP/WsMESs5+MCflVvnBRdcQP/+/WnevDmXX345c+bM4aKLLkISX375Jd27d2f+/PnstttumQ7rdtkl/R2xnnIiMLPUbdp0My654lo++uB9Bv3mTFpstQ0AM+fMY5fOme7FXp87jxUrVjB3zjxat2tNyzYt2anLTvz1zr+y3QfBsmWZt5hld1W9/369OP7kY5DEgF8OLLfOnj17cvDBB3PFFVfw2GOP0bFjR4477ji6du0KwPLly3nqqaeYMWMG3bt3Z+bM9PpaWt85EZgZkO7F3gfvHc7T/3qUr7/+ihNOO5sxo+7joF+cSfPNmq6qs+UWzegz4Dze+XQJg28eTLMtmrHvAfvS/5D+bLyiAT/u3p2LTz213HI3bLwhTZtuRqNGjfje975XblqfPn34+uuvARg1ahQ9e/Zk4MCBLFmyhAYNGnDrrbdy/vnnc8wxx7DVVlux1VZbpbb96zsnAjNL3XEnncZxJ522arz3zw4r1+ncgoXv0WqbLbnn+svLdTHR95i+9D2mb7lO557++9/LLXvYDXeWG584cSIA48aNqxTH6NGjK5VNmTJlDbem/vFzBGZmRc6JwMwKrl3rbbnn+ssLHUbRciIwMytyTgRmZkXOicDMrMg5EZhZvbK+dDp3x4hH8q77xMSJ/Ou559ZqPRMmTGDQoEFrNW8Z3z5qZgDceOoz6zT/r4b2rKFI8rO+dDq3cuXKcg+5lbljxBgG9OuTV91ee++dWnz5cCIws9TV5U7nhg8fztixY1myZAmNGzdm1KhRTJo0ib/85S9EBAce+UtWrFjB8JuHsGLFck45+wKWLVvKzDfm0eOIk7nkrBO5fMjtdO/yfWYvWswJp5/A4EsGs3TpUnr8bw8GnjuQux95hOUrVtDzhz/k1D/8gc2bNg9Qn8IAAAyfSURBVGX++x9x1633s+02Lbn2uquYOOk51EDcc9/fadeuHQMGDOCdd96hbdu2tG7dep0+HzcNmVnqyjqdu23kGFq2aZuzzgeLPuahW6/mossv4vbrb+fTxZ+u6nTugSFDuHJo5i237374Idf/4Q9cctppNG+2BaXvLuSdhW9X2enc+PHj2WabbRg8eDAXX3wx48ePp0mTJkyePJmrr76aa6+9lgcffJD333+/yvibNm3KuHHj2GuvvXj44YcBWLp0KY8++ih7/Xh//n7LDdw6cgy3P/AYw2+5nh69DmLnTjsw4cFbOWDfHwLQt/d+XHXzVbTboR13/uNO7nv8PiY/O5lvv/m23Lo+/fxz7rnmGk456Qwe+9cYZr8xi/c/eI/RI//J4Muu5corr+Sll16ipKSEp556iu23336dPhvwGYGZ1YK63uncbrvtBkCXLl2YOnUqW2+9NbvvvjsAn36ymPnz3uSUozPNQJ8s/piIqLSMrrvsyL+Bd995l6v/cDXffvMtb817i08+/qRcvc7bbUeDBg3YZqttWLBgPv+eN5dJUybS96iDAWjTvtWquAG6du3K5MmTV/sZVMeJwMxSV9c7nZsxY8aqf8t+gZfFsXmz5nTotCM33/MQJSUlLFu2DElI5ZfRoEGmYOSdIxlw1gC6/6g7vzj4F5WShrJmjAh22K4DP96nJ1f+8erM+rbdkFdeeYXx48cD8Oqrr1a77/PhRGBmQLoXe+t6p3OLFy+mV69eq64RZP8Cb9CgAb84+XQG9jsUJLbv0JHfXn4N3bvsRJ8B5/HrU44rt6x9D9iXKy66gu3/Z3sabdCo4qoq+f6OO7Nliy0zZwQS/U84joEDB3LzzTez//7707ZtW9q0abPa5VTHicDMUlfXO53r3bs3J5100qrxHj160KNHj1Xj+/TsxT49e5Wb59pLz1s1POHBW1cN773/3uy9f/m7hPbp893dRXcMHgzAj/bchx/tuQ8A557xG8494zcAbNl2UyBzEbumOBGYmSXmzp3LKaecsmp8ww035KijjipgRLXDicDMCm596XSuY8eOTJgwodBh1DrfPmpW5HLd4WJ125p+pk4EZkWscePGLF682MmgHokIFi9eTOPGjfOex01DZkWsVatWlJaWsmjRotTW8eGn3+Qsn6Pc6/ygYeXD0orPcy/728+WVSpb/HX+B8CasCbbl2vbIPf25do2yG/7GjduTKtWrVZbr0yqiUBSb+A6oAS4LSIGV1HvB8CLwFER8WCaMZnZdxo1akT79u1TXceBF/0zZ/mCxsfkLD+yfeVbIR+4cnnOus/3uLFSWW33ebQm25dr2yD39uXaNkhn+1JrGpJUAtwIHAjsCBwtaccq6l0FVL7Xy8zMUpfmNYLuwLyImB8RS4ERwKE56p0JPAR8lGIsZmZWBaV1kUjSEUDviDgpGf8FsEdEnJFVpyVwH9ATuB14LFfTkKSBQNnz4x2BuakEndsWwMe1uL7a5u2ru+rztoG3r6a1jYgWuSakeY1AOcoqZp2/ARdGxApV7Jgje6aIYcCwGowtb5KmRUS3Qqy7Nnj76q76vG3g7atNaSaCUiC7k+xWwHsV6nQDRiRJYAvgIEnLIyL/V/uYmdk6STMRTAU6SGoPvAv0A8pdRo+IVbcrSBpOpmnIScDMrBallggiYrmkM8jcDVQC3BERsySdmkwfmta6a1hBmqRqkbev7qrP2wbevlqT2sViMzOrG9zFhJlZkXMiMDMrck4EZmZFzp3OFRlJ3YGIiKlJlx+9gTciYmyBQzOzAvEZQZ4knVDoGNaVpEuBIcDNkq4EbgA2AS6SdElBg7NqJR04lg03lXS7pNck3Sep6pft1hHJNg2W9IakxcnfnKRss0LHV9/5rqE8SXonItbtDdEFJmkm0AX4HvAB0CoiPpe0ITAlInYpaIDrSFJT4GKgD1D2KP1HwD+AwRHxWaFiW1eSXomI3ZPh28h8frcChwE/jog+1c2/vpM0DngGuCsiPkjKtgb6Az+JiAMKGV9NUObJ2e5ASzK9LLwHvBTrwUHYTUNZJL1W1SSgzv/qApZHxArga0n/iYjPASLiG0krCxxbTXiAzMGkR46DySigzh9MEt0ioksy/FdJ/QsaTc1oFxFXZRckn+FVkgYUKKYaI6kXcBPwbzIP2EKmt4UdJJ0eEU8ULDicCCraCvhf4NMK5QIm1X44NW6ppI0i4muga1lh8ku6PiSC+nww2VLSeWS+i5tKUtYvyfrQxPu2pAvInBF8CJA0eR0PLCxkYDXkOjJnNguyC5OeF8YCnQsRVJn68AWqSY8Bm0TE2xX+FgATChtajdg3SQJERPaBvxGZX8113duSLshuM5e0laQLqfsHk1uBJmSu6dxFpm+usjOe6QWMq6YcBTQHnpX0qaRPyPyfawYcWcjAakhDMv2vVfQumf9/BeVrBFZvSNocuIjMey+2TIo/BMaQuUZQ8UyvTpHUiUz78pSI+DKrvHdEPF64yGqepH3ItKfPLHSzSU2QdDGZhDaC736UtCbTB9sDEXFloWIDJwIrEpJOiIg7Cx3H2pJ0JnAGMIfMBf+zI+IfybRVF5LrKkkvRUT3ZPgk4FfAI0Av4NGqXnNblyS3a/+MTDIXmTOEMRExu6CB4URgRaKu3/WV3PG1Z0R8Kakd8CBwd0RcJ+nViNitoAGuo+xtkDQVOCgiFknaGHgxInYubIT1my8WW71Rz+/6KilrDoqIBZJ6AA9Kakvul0DVNQ2Spr0GZH6gLgKIiK8k5X5zfR2yvt/a7ERg9Ul9vuvrA0ldImI6QHJm8FPgDqA+/FpuCrxM5rMKSVtHxAeSNqF+JLqqbm0+nvXg1mY3DVm9Iel24M6ImJhj2n0RcUyO2eoESa3IPAfyQY5pP4qIFwoQVuokbQRsFRFvFTqWdSFpbkR0XNNptcWJwMwsZZKeAJ4i93MSB0TETwoYnp8jMDOrBdnPSXxS4TmJnxcyMPAZgZlZQa0PtzY7EZiZFdD6cGuz7xoyM0vZ+n5rsxOBmVn61utbm50IzMzSV9ahZaUOAiVNqP1wKsTgawRmZsXNt4+amRU5JwIzsyLnRGB1iqRLJM1KXtw+XdIeq6k/SNL5yfD/SfpJMnxO0n1BrnkmSJoraYakFyQV5PF/SX2SrovNUuVEYHWGpD2BnwK7R8QuwE9YgzePRcQfIuKpZPQcIGciSBwbEbuSeRvY1WsQY03egNEHcCKw1DkRWF2yDfBxRPwXICI+joj3ACQtkHSVpJeSvx0qzixpuKQjJJ0FbAuMlzR+Net8Dtghmb+rpGclvSxpnKRtkvIJkq6Q9CxwdvJ6zNHJGcUMSXsl9Y5LYpsu6RZJJUn5l5IuT+q+mMy/F5mXmFyd1N9e0smSpib1Hio7o0mmvZhM+z9J2W8v+01S/pqkP67Lzrf6y4nA6pIngNaS3pR0k6QfV5j+efKWqxuAv1W1kIgYArwH7BcR+61mnYcAMyU1Aq4HjoiIrmS6f748q95mEfHjiLgWGAI8m5xR7A7MktSZTH8zP4qILsAK4Nhk3rKXr+xKJvGcHBGTyLxi8zcR0SUi/gM8HBE/SOrNAU5M5r8OuC4ifpBsFwCSegEdyLzysQvQVdK+q9leK0J+jsDqjKQP/q7APsB+wEhJF0XE8KTK/Vn//nUdV3evpG+ABcCZQEdgJ+BJSQAlwPtZ9UdmDfcEfpnEvAJYIukXQFdgajL/hmReTAKwlMx95pDpk7+qvul3kvQnYDMyL7Efl5TvSaYZCeA+4JpkuFfy92oyvgmZxPDc6jbeiosTgdUpyYF1AjAheX1jf2B42eTsquu4qmMjYlrZiKTNgFkRsWcV9b9azfJEpgvii3NMWxbfPdCzgqr/Xw4H+kTEDEnHAz3yWOeVEXHLaupZkXPTkNUZkjpK6pBV1AV4O2v8qKx/J69mcV8ATdZg9XOBFskFayQ1kvT9Kuo+DZyW1CuRtGlSdoSkLZPyZslrJtckxibA+0kz1bFZ5S8ChyfD/bLKxwEDkrd8Iall2frNsjkRWF2yCXCXpNlJJ147AoOypn9P0hTgbODc1SxrGPCvPC4WAxARS4EjgKskzQCmA3tVUf1sYL/kjOVl4PsRMRv4HfBEEvuTZC5+V2cE8BtJr0raHvg9MCWZ942seucA50l6KVnmkiTmJ8g0FU1OYnmQNUt+ViTcxYTVC5IWAN0i4uNCx1LbkruHvomIkNQPODoiDi10XFZ3+BqBWd3XFbhBmavQnwEDChyP1TE+IzAzK3K+RmBmVuScCMzMipwTgZlZkXMiMDMrck4EZmZF7v8BQiwcbm0TC9gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_results(new_data, 'basic labeling for different splits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-garbage",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
